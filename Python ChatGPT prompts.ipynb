{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3540da9",
   "metadata": {},
   "source": [
    "<h1><span style=\"color: orange\">Jupyter Notebook Tutorial</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b65855",
   "metadata": {},
   "source": [
    "<h2><span style=\"color: orange\">1. Make and interactive 3D Plot</span></h2>\n",
    "<h3><span style=\"color: orange\">1.1 Basic Figure</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe1b1b",
   "metadata": {},
   "source": [
    "<b>Write a python script that generates a 3d scatter plot from 100 randomly generated points</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edfdd57",
   "metadata": {},
   "source": [
    "<blockquote>Here is a Python script that generates a 3D scatter plot from 100 randomly generated points:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f60bf7",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate random data for 3D scatter plot\n",
    "x_data = np.random.rand(100)\n",
    "y_data = np.random.rand(100)\n",
    "z_data = np.random.rand(100)\n",
    "\n",
    "# Create a 3D scatter plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(x_data, y_data, z_data, c='r', marker='o')\n",
    "\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea358aa2",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: orange\">1.2 Updating a query</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee228dc",
   "metadata": {},
   "source": [
    "<b>If I were to paste that in a python notebook, would the plot be interactive? Can i rotate it?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55af07fc",
   "metadata": {},
   "source": [
    "<blockquote>The plot generated by the code I provided will be static if displayed within a Jupyter Notebook using the inline backend. To make it interactive, allowing you to rotate the plot, you can use %matplotlib notebook as a magic command at the top of your notebook cell. This will enable the notebook backend and make the plot interactive.\n",
    "\n",
    "Here's how to modify the notebook cell:</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8ee38a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# Importing necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate random data for 3D scatter plot\n",
    "x_data = np.random.rand(100)\n",
    "y_data = np.random.rand(100)\n",
    "z_data = np.random.rand(100)\n",
    "\n",
    "# Create a 3D scatter plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(x_data, y_data, z_data, c='r', marker='o')\n",
    "\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94797b5a",
   "metadata": {},
   "source": [
    "<b>Now, I want you to detect a left mouse click on a point, and highlight this point. A little box should then appear andand indicate the point index, the X Y and Z coordinate and the point value</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7ea078",
   "metadata": {},
   "source": [
    "<blockquote>The above plot is interactive and allows you to click on a point to highlight it. A small box appears showing the index, X, \n",
    "Y, and Z coordinates, as well as the point value, which is calculated as the Euclidean distance to the origin for demonstration purposes.\n",
    "\n",
    "Here is the modified code to add this functionality:</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the figure and 3D axis\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(42)  # for reproducibility\n",
    "x_data = np.random.rand(100)\n",
    "y_data = np.random.rand(100)\n",
    "z_data = np.random.rand(100)\n",
    "\n",
    "# Point values (can be any metric you want to display, here we use Euclidean distance to the origin for demonstration)\n",
    "point_values = np.sqrt(x_data**2 + y_data**2 + z_data**2)\n",
    "\n",
    "# Create the scatter plot\n",
    "scatter = ax.scatter(x_data, y_data, z_data, c='r', marker='o')\n",
    "\n",
    "# Function to annotate a selected point\n",
    "def on_pick(event):\n",
    "    ind = event.ind[0]\n",
    "    x, y, z = x_data[ind], y_data[ind], z_data[ind]\n",
    "    value = point_values[ind]\n",
    "    \n",
    "    # Highlight the selected point\n",
    "    ax.scatter(x, y, z, c='blue', s=100, marker='o', zorder=5)\n",
    "    \n",
    "    # Annotate the selected point\n",
    "    annotation = f'Index: {ind}\\nX: {x:.2f}\\nY: {y:.2f}\\nZ: {z:.2f}\\nValue: {value:.2f}'\n",
    "    ax.text(x, y, z, annotation, bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white'))\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "# Connect the pick event to the function\n",
    "fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "\n",
    "# Enable picking\n",
    "scatter.set_picker(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21294966",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: orange\">1.3 Debugging</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc75e7",
   "metadata": {},
   "source": [
    "Debbuging is usually an iterative process\n",
    "\n",
    "<b>The text box appear but the wrong Point is selected, and the previous box doesn't clear up. Please fix this</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d001d",
   "metadata": {},
   "source": [
    "<blockquote>The updated code now properly highlights the clicked point in blue and shows a text box with relevant details. The previous annotations and highlights are removed when you click a new point.\n",
    "\n",
    "Here's the updated code that addresses these issues:</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3fa077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the figure and 3D axis\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(42)  # for reproducibility\n",
    "x_data = np.random.rand(100)\n",
    "y_data = np.random.rand(100)\n",
    "z_data = np.random.rand(100)\n",
    "\n",
    "# Point values (can be any metric you want to display, here we use Euclidean distance to the origin for demonstration)\n",
    "point_values = np.sqrt(x_data**2 + y_data**2 + z_data**2)\n",
    "\n",
    "# Create the scatter plot\n",
    "scatter = ax.scatter(x_data, y_data, z_data, c='r', picker=True, marker='o')\n",
    "\n",
    "# Store the currently displayed annotation for removal later\n",
    "current_annotation = None\n",
    "current_highlight = None\n",
    "\n",
    "# Function to annotate and highlight a selected point\n",
    "def on_pick(event):\n",
    "    global current_annotation, current_highlight\n",
    "    # Remove the previous annotation and highlight, if they exist\n",
    "    if current_annotation:\n",
    "        current_annotation.remove()\n",
    "    if current_highlight:\n",
    "        current_highlight.remove()\n",
    "    \n",
    "    # Get the index of the selected point\n",
    "    ind = event.ind[0]\n",
    "    x, y, z = x_data[ind], y_data[ind], z_data[ind]\n",
    "    value = point_values[ind]\n",
    "    \n",
    "    # Highlight the selected point\n",
    "    current_highlight = ax.scatter(x, y, z, c='blue', s=100, zorder=5)\n",
    "    \n",
    "    # Annotate the selected point\n",
    "    annotation_text = f'Index: {ind}\\nX: {x:.2f}\\nY: {y:.2f}\\nZ: {z:.2f}\\nValue: {value:.2f}'\n",
    "    current_annotation = ax.text(x, y, z, annotation_text, bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white'))\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    \n",
    "# Connect the pick event to the function\n",
    "fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18b5112",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<b>Only one box is displayed now, but the point is not highlighted anymore. I am not sure that the correct point(the one i click on ) is selected. Please explain how we know what point I click on from the 3d projection</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8c83d",
   "metadata": {},
   "source": [
    "<i>--> Above code didn't fix the issue. Updating the prompt</i>\n",
    "\n",
    "<b>Only one box is displayed now, but the point is not visible anymore. Can we space out the box and the point by a little\n",
    "The correct point is not selected (it selects a point at a totally different location). \n",
    "Please explain how we know what point I click on from the 3d projection, and fix the code</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3137b9af",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<blockquote>The process of selecting a point in a 3D scatter plot is slightly more complicated than in a 2D plot because you're dealing with a projection of 3D data onto a 2D screen. When you click on a point in the 3D scatter plot, the plot library (Matplotlib in this case) uses the 2D coordinates of your mouse click and tries to find the closest 3D data point(s) that are projected onto that position. This is why sometimes the point that appears to be under the mouse cursor in the 3D visualization might not be the one that gets selected.\n",
    "\n",
    "Regarding the issues you mentioned:\n",
    "\n",
    "Point Not Visible: The newly plotted point is plotted at the same coordinates as the old point, making it obscure. We can slightly offset the new point or the text box to make both visible.\n",
    "\n",
    "Incorrect Point Selected: This could be due to how Matplotlib handles 'pick' events in 3D plots. The 3D data are projected onto a 2D plane, and Matplotlib checks if your click is \"close enough\" to this projection. This can sometimes lead to picking the wrong point, especially if points are close together in the projected view.\n",
    "\n",
    "Let's try to address these issues in the code.</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bae50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the figure and 3D axis again for a fresh start\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Generate random data again (using the same seed for reproducibility)\n",
    "np.random.seed(42)\n",
    "x_data = np.random.rand(100)\n",
    "y_data = np.random.rand(100)\n",
    "z_data = np.random.rand(100)\n",
    "\n",
    "# Point values\n",
    "point_values = np.sqrt(x_data**2 + y_data**2 + z_data**2)\n",
    "\n",
    "# Create the scatter plot\n",
    "scatter = ax.scatter(x_data, y_data, z_data, c='r', picker=True, marker='o')\n",
    "\n",
    "# Variables to store the currently displayed annotation and highlight\n",
    "current_annotation = None\n",
    "current_highlight = None\n",
    "\n",
    "# Offset for the annotation box (in data coordinates)\n",
    "offset = 0.05\n",
    "\n",
    "# Function to annotate and highlight a selected point\n",
    "def on_pick(event):\n",
    "    global current_annotation, current_highlight\n",
    "    # Remove the previous annotation and highlight, if they exist\n",
    "    if current_annotation:\n",
    "        current_annotation.remove()\n",
    "    if current_highlight:\n",
    "        current_highlight.remove()\n",
    "    \n",
    "    # Get the index of the selected point\n",
    "    ind = event.ind[0]\n",
    "    x, y, z = x_data[ind], y_data[ind], z_data[ind]\n",
    "    value = point_values[ind]\n",
    "    \n",
    "    # Highlight the selected point with a slight offset to make it visible\n",
    "    current_highlight = ax.scatter(x, y, z, c='blue', s=100, zorder=5)\n",
    "    \n",
    "    # Annotate the selected point with a slight offset for visibility\n",
    "    annotation_text = f'Index: {ind}\\nX: {x:.2f}\\nY: {y:.2f}\\nZ: {z:.2f}\\nValue: {value:.2f}'\n",
    "    current_annotation = ax.text(x + offset, y + offset, z + offset, annotation_text, \n",
    "                                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white'))\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    \n",
    "# Connect the pick event to the function\n",
    "fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc84d844",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: orange\">1.4 Manual Intervention\n",
    "</span></h3>\n",
    "\n",
    "<b><u><span style=\"color: #1d1da3\"><span style=\"color: #1d1da3\">Guiding the AI with known examples</span></span>\n",
    "</u></b>\n",
    "\n",
    "<b>X and Y values displayed in the box (the selected point) are mirrored compared to the value i see from the live display, when hoovering over the mouse. 0.6 becomes 0.4, 0.1 becomes 0.9. This is partiuclarly obvious from the top vew where Z is not involved.\n",
    "\n",
    "<b>If i do the following\n",
    "\n",
    "<pre><code>Generate random data again (using the same seed for reproducibility)\n",
    "np.random.seed(42)\n",
    "x_data = np.array([0,0.2,0.5,1])\n",
    "y_data = np.array([0,0,0,0])\n",
    "z_data = np.array([0,0,0,0])</code></pre>\n",
    "\n",
    "<b>and the 3d plot shows Decreasing X values front to back, it works (x = 1 is closer to me than x = 0) and as soone as X = 0 becomes closer, the points selected are inverted. So if i click onthe point with value 0 it higlight the one with value 1 and vice versa.\n",
    "\n",
    "<b>Find a known correction to revert the axes in this case, or write one</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95755615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the figure and 3D axis again for a fresh start\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Generate random data again (using the same seed for reproducibility)\n",
    "np.random.seed(42)\n",
    "x_data = np.array([0,0.2,0.5,1])\n",
    "y_data = np.array([0,0,0,0])\n",
    "z_data = np.array([0,0,0,0])\n",
    "\n",
    "# Point values\n",
    "point_values = np.sqrt(x_data**2 + y_data**2 + z_data**2)\n",
    "\n",
    "# Create the scatter plot\n",
    "scatter = ax.scatter(x_data, y_data, z_data, c=point_values, picker=True, marker='o')\n",
    "\n",
    "# Variables to store the currently displayed annotation and highlight\n",
    "current_annotation = None\n",
    "current_highlight = None\n",
    "\n",
    "# Offset for the annotation box (in data coordinates)\n",
    "offset = 0.05\n",
    "\n",
    "# Function to annotate and highlight a selected point\n",
    "def on_pick(event):\n",
    "    global current_annotation, current_highlight\n",
    "    # Remove the previous annotation and highlight, if they exist\n",
    "    if current_annotation:\n",
    "        current_annotation.remove()\n",
    "    if current_highlight:\n",
    "        current_highlight.remove()\n",
    "    \n",
    "    # Get the index of the selected point\n",
    "    ind = event.ind[0]\n",
    "    x, y, z = x_data[ind], y_data[ind], z_data[ind]\n",
    "    value = point_values[ind]\n",
    "    \n",
    "    # Highlight the selected point with a slight offset to make it visible\n",
    "    current_highlight = ax.scatter(x, y, z, c='blue', s=100, zorder=5)\n",
    "    \n",
    "    # Annotate the selected point with a slight offset for visibility\n",
    "    annotation_text = f'Index: {ind}\\nX: {x:.2f}\\nY: {y:.2f}\\nZ: {z:.2f}\\nValue: {value:.2f}'\n",
    "    current_annotation = ax.text(x + offset, y + offset, z + offset, annotation_text, \n",
    "                                 bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white'))\n",
    "    \n",
    "    # Debug: Display mouse click coordinates\n",
    "    mouse_x, mouse_y = event.mouseevent.xdata, event.mouseevent.ydata\n",
    "    print(f\"Mouse click coordinates: X: {mouse_x}, Y: {mouse_y}\")\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    \n",
    "# Connect the pick event to the function\n",
    "fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5148ac00",
   "metadata": {},
   "source": [
    "[...]\n",
    "\n",
    "<blockquote>The issue you're encountering seems related to the orientation of the plot. When the orientation changes such that the axis with a value of 0 is closer to the viewer than the axis with a value of 1, the pick_event starts to behave in a mirrored manner.\n",
    "\n",
    "One approach to correct for this behavior is to calculate the view angle and use it to determine whether to flip the selection index. We can use ax.elev and ax.azim to get the elevation and azimuth angles, respectively. These angles describe the orientation of the 3D plot.\n",
    "\n",
    "Here's how we can modify the code to include a conditional flipping based on the azimuth angle:</blockquote>\n",
    "\n",
    "[...]\n",
    "\n",
    "<b>it is still reversed</b>\n",
    "\n",
    "\n",
    "[...]\n",
    "\n",
    "<blockquote>I apologize for the confusion. The issue seems to stem from the intrinsic complexities in how 3D picking works with Matplotlib, especially when the orientation of the axis changes. The azimuth and elevation angles might not provide a straightforward way to determine the axis reversal in this specific case.\n",
    "\n",
    "An alternative approach is to directly compute the distances between the mouse click point (in 2D coordinates) and the projected 2D coordinates of all 3D points, then select the closest one. This way, you're taking control over the picking mechanism.\n",
    "\n",
    "Here's a code snippet that attempts to do just that:</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96289e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import proj3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n",
    "\n",
    "def on_click(event):\n",
    "    global current_annotation, current_highlight\n",
    "    if current_annotation:\n",
    "        current_annotation.remove()\n",
    "    if current_highlight:\n",
    "        current_highlight.remove()\n",
    "\n",
    "    if event.inaxes == ax:\n",
    "        # Convert 3D coordinates to 2D projection\n",
    "        x2, y2, _ = proj3d.proj_transform(x_data, y_data, z_data, ax.get_proj())\n",
    "        \n",
    "        min_distance = float('inf')\n",
    "        ind = None\n",
    "        \n",
    "        # Find closest point\n",
    "        for i in range(len(x2)):\n",
    "            d = distance((x2[i], y2[i]), (event.xdata, event.ydata))\n",
    "            if d < min_distance:\n",
    "                ind = i\n",
    "                min_distance = d\n",
    "            \n",
    "        x, y, z = x_data[ind], y_data[ind], z_data[ind]\n",
    "        \n",
    "        current_highlight = ax.scatter(x, y, z, c='blue', s=100, zorder=5)\n",
    "        \n",
    "        annotation_text = f'Index: {ind}\\nX: {x:.2f}\\nY: {y:.2f}\\nZ: {z:.2f}'\n",
    "        current_annotation = ax.text(x + offset, y + offset, z + offset, annotation_text,\n",
    "                                     bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white'))\n",
    "        \n",
    "        plt.draw()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Generate your specific data\n",
    "x_data = np.random.rand(100)\n",
    "y_data = np.random.rand(100)\n",
    "z_data = np.random.rand(100)\n",
    "\n",
    "scatter = ax.scatter(x_data, y_data, z_data, c=np.arange(100), picker=True, marker='o')\n",
    "\n",
    "current_annotation = None\n",
    "current_highlight = None\n",
    "offset = 0.05\n",
    "\n",
    "fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3755557",
   "metadata": {},
   "source": [
    "<h2><span style=\"color: orange\">2 Load and display images</span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ddd47d",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: orange\">2.1 Loading\n",
    "</span></h3>\n",
    "\n",
    "<b>Load this tiff file and display the images of  channels 1 to 3 and an overlay in 4 subplots arranged in a square layout. You may have to split the channels first. Use PIL</b>\n",
    "\n",
    "<i>--> First answer returned an error from the GPT sandbox, although it may have worked. I asked to use PIL</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f84e8",
   "metadata": {},
   "source": [
    "<blockquote>To load and display the TIFF file using PIL (Pillow), we can follow these steps:\n",
    "\n",
    "Load the TIFF file using Image.open().\n",
    "Extract the individual channels from the image.\n",
    "Display the individual channels and an overlay in 4 subplots arranged in a square layout using matplotlib.</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91422a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Specify the path to the TIFF file (this may vary, so it's kept as a variable)\n",
    "tiff_file_path = 'new_im.tiff'\n",
    "\n",
    "# Open the new TIFF image using PIL\n",
    "new_image = Image.open(tiff_file_path)\n",
    "\n",
    "# Convert the new image to an RGB format (if it isn't already)\n",
    "new_image_rgb = new_image.convert(\"RGB\")\n",
    "\n",
    "# Split the new image into its individual R, G, B channels\n",
    "r_new, g_new, b_new = new_image_rgb.split()\n",
    "\n",
    "# Generate an overlay image by merging the channels\n",
    "overlay_new = ImageOps.colorize(new_image_rgb.convert(\"L\"), \"#000000\", \"#FFFFFF\")\n",
    "\n",
    "# Create a 2x2 grid for subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(9, 10))\n",
    "\n",
    "# Plot individual channels and overlay for the new image\n",
    "axs[0, 0].imshow(r_new, cmap='gray')\n",
    "axs[0, 0].set_title('Channel 1 (Red)')\n",
    "axs[0, 0].axis('off')\n",
    "\n",
    "axs[0, 1].imshow(g_new, cmap='gray')\n",
    "axs[0, 1].set_title('Channel 2 (Green)')\n",
    "axs[0, 1].axis('off')\n",
    "\n",
    "axs[1, 0].imshow(b_new, cmap='gray')\n",
    "axs[1, 0].set_title('Channel 3 (Blue)')\n",
    "axs[1, 0].axis('off')\n",
    "\n",
    "axs[1, 1].imshow(overlay_new, cmap='gray')\n",
    "axs[1, 1].set_title('Overlay')\n",
    "axs[1, 1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ca7bc",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: orange\">2.2 Expressing problems in natural langage is convenient. \n",
    "</span></h3>\n",
    "\n",
    "<b>Now let's extract the mean signal per channel from the different cell bodies of this image. There are few fairly circular objects in this image, that are at least more than 50 pixels large.\n",
    "\n",
    "1. Detect these object on the overlay. Plot an estimateof the background and of the signal iteself. Explain how you seperated the background from the signal.\n",
    "2. Build a mask around them and Plot the mask on the overlay\n",
    "3. Extract the mean signal in each one of them and plot the absolute value of each cell in a 3D scatter, where the color of the point represent the color of the cell\n",
    "4. Make a ternary plot of their brightnesses\n",
    "\n",
    "<b>let's do this one step at the time</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a541a91",
   "metadata": {},
   "source": [
    "<blockquote>Certainly, let's take it one step at a time.\n",
    "\n",
    "Step 1: Detect Objects on the Overlay and Estimate Background and Signal\n",
    "For detecting circular objects in the image, we can use image processing techniques such as thresholding, morphological operations, and contour detection. The idea is to separate the objects from the background by selecting a proper threshold level.\n",
    "\n",
    "1. Convert the overlay image to a grayscale image.\n",
    "2. Apply thresholding to separate the background from the objects.\n",
    "3. Use morphological operations to remove noise and separate objects more clearly.\n",
    "4. Find contours to detect the objects.\n",
    "\n",
    "Let's start by implementing these steps.</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d87b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import closing, disk\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Convert the overlay image to a NumPy array and then to grayscale\n",
    "overlay_array = np.array(overlay_new)\n",
    "overlay_gray = rgb2gray(overlay_array)\n",
    "\n",
    "# Use Otsu's method to find an optimal threshold value\n",
    "thresh = threshold_otsu(overlay_gray)\n",
    "binary = overlay_gray > thresh\n",
    "\n",
    "# Apply morphological closing to fill small holes\n",
    "selem = disk(3)\n",
    "binary_closed = closing(binary, selem)\n",
    "\n",
    "# Label connected regions in the binary image\n",
    "labels = measure.label(binary_closed, background=0)\n",
    "\n",
    "# Create a plot to show original overlay, binary image, and labeled regions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(9, 5))\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(overlay_gray, cmap='gray')\n",
    "ax[0].set_title('Original Overlay')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(binary, cmap='gray')\n",
    "ax[1].set_title('Binary Image')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(labels, cmap='nipy_spectral')\n",
    "ax[2].set_title('Labeled Regions')\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Estimate background and signal\n",
    "background_estimate = overlay_gray[binary == 0].mean()\n",
    "signal_estimate = overlay_gray[binary == 1].mean()\n",
    "\n",
    "background_estimate, signal_estimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf76a108",
   "metadata": {},
   "source": [
    "<blockquote>Step 1: Explanation and Estimates\n",
    "Images:\n",
    "\n",
    "The first image is the original overlay in grayscale.\n",
    "The second image is the binary version of the overlay after applying Otsu's thresholding.\n",
    "The third image shows labeled regions representing different objects in the image.\n",
    "Estimates:\n",
    "\n",
    "Background mean intensity: \n",
    "≈\n",
    "0.0116\n",
    "≈0.0116\n",
    "Signal mean intensity: \n",
    "≈\n",
    "0.2071\n",
    "≈0.2071\n",
    "Separation of Background from Signal:\n",
    "\n",
    "Otsu's method was used for thresholding, which automatically calculates an optimal threshold value to separate the background and the objects (signal) based on their intensities.\n",
    "Morphological closing operation was applied to fill small holes in the objects for better labeling.</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd659c1",
   "metadata": {},
   "source": [
    "<b>yes but keep only the 5 largest objects</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc5f2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "\n",
    "# Compute the area of each labeled region\n",
    "props = regionprops(labels)\n",
    "areas = [prop.area for prop in props]\n",
    "\n",
    "# Sort areas and keep only the 5 largest objects\n",
    "sorted_areas = sorted(areas, reverse=True)[:5]\n",
    "\n",
    "# Create a mask for the 5 largest objects\n",
    "mask_largest_5 = np.zeros_like(labels)\n",
    "for i, prop in enumerate(props):\n",
    "    if prop.area in sorted_areas:\n",
    "        mask_largest_5[labels == i + 1] = 1\n",
    "\n",
    "# Overlay the mask on the original overlay image\n",
    "overlay_with_mask = overlay_gray.copy()\n",
    "overlay_with_mask[mask_largest_5 == 1] = 1  # Set mask area to white (1)\n",
    "\n",
    "# Create a plot to show the mask and the overlay with mask\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(mask_largest_5, cmap='gray')\n",
    "ax[0].set_title('Mask of 5 Largest Objects')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(overlay_with_mask, cmap='gray')\n",
    "ax[1].set_title('Overlay with Mask')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd2117",
   "metadata": {},
   "source": [
    "<blockquote>Step 2: Mask of the 5 Largest Objects\n",
    "Images:\n",
    "\n",
    "The first image shows a mask created for the 5 largest objects in the overlay.\n",
    "The second image shows the original overlay with the mask applied. The areas corresponding to the 5 largest objects are highlighted.\n",
    "The mask was created by first identifying the areas of all labeled regions and then selecting the 5 largest areas. The corresponding regions were then highlighted in the mask.\n",
    "\n",
    "Would you like to proceed to Step 3 for extracting the mean signal from these 5 largest objects?</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb715f40",
   "metadata": {},
   "source": [
    "<b>yes proceed to the next step</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1f1124",
   "metadata": {},
   "source": [
    "<blockquote>Step 3: Mean Signals from the 5 Largest Objects\n",
    "3D Scatter Plot:\n",
    "\n",
    "The 3D scatter plot shows the mean signals in the Red, Green, and Blue channels for each of the 5 largest objects. Each point is colored based on its mean signal in each channel.\n",
    "Mean Signals:\n",
    "\n",
    "Red Channel: \n",
    "[\n",
    "80.37\n",
    ",\n",
    "54.10\n",
    ",\n",
    "67.71\n",
    ",\n",
    "49.30\n",
    ",\n",
    "26.06\n",
    "]\n",
    "[80.37,54.10,67.71,49.30,26.06]\n",
    "Green Channel: \n",
    "[\n",
    "38.92\n",
    ",\n",
    "70.89\n",
    ",\n",
    "71.49\n",
    ",\n",
    "13.69\n",
    ",\n",
    "26.41\n",
    "]\n",
    "[38.92,70.89,71.49,13.69,26.41]\n",
    "Blue Channel: \n",
    "[\n",
    "32.49\n",
    ",\n",
    "16.04\n",
    ",\n",
    "18.38\n",
    ",\n",
    "10.08\n",
    ",\n",
    "11.49\n",
    "]\n",
    "[32.49,16.04,18.38,10.08,11.49]\n",
    "Shall we move on to Step 4 to make a ternary plot of their brightnesses?</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store mean signals for each channel and each object\n",
    "mean_signals_r = []\n",
    "mean_signals_g = []\n",
    "mean_signals_b = []\n",
    "\n",
    "# Convert PIL images to NumPy arrays for calculations\n",
    "r_array = np.array(r_new)\n",
    "g_array = np.array(g_new)\n",
    "b_array = np.array(b_new)\n",
    "\n",
    "# Loop through each object in the mask to calculate the mean signal in each channel\n",
    "for i, area in enumerate(sorted_areas):\n",
    "    object_mask = (labels == areas.index(area) + 1)\n",
    "    mean_r = r_array[object_mask].mean()\n",
    "    mean_g = g_array[object_mask].mean()\n",
    "    mean_b = b_array[object_mask].mean()\n",
    "    \n",
    "    mean_signals_r.append(mean_r)\n",
    "    mean_signals_g.append(mean_g)\n",
    "    mean_signals_b.append(mean_b)\n",
    "\n",
    "# Plot the mean signals in a 3D scatter plot\n",
    "fig = plt.figure(figsize=(9, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Set color based on the mean signal for each channel\n",
    "colors = [(r/255, g/255, b/255) for r, g, b in zip(mean_signals_r, mean_signals_g, mean_signals_b)]\n",
    "\n",
    "# Plot each point\n",
    "for r, g, b, color in zip(mean_signals_r, mean_signals_g, mean_signals_b, colors):\n",
    "    ax.scatter(r, g, b, c=[color], s=100)\n",
    "\n",
    "# Labeling and grid\n",
    "ax.set_xlabel('Mean Signal in Red Channel')\n",
    "ax.set_ylabel('Mean Signal in Green Channel')\n",
    "ax.set_zlabel('Mean Signal in Blue Channel')\n",
    "ax.set_title('3D Scatter Plot of Mean Signals')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Return the mean signals for review\n",
    "mean_signals_r, mean_signals_g, mean_signals_b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4ddd92",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: orange\">2.3 Styling, Color etc...\n",
    "</span></h3>\n",
    "\n",
    "<b>let's adjust the colors first. They are all a bit dark because the image is dark. Let make the colors more vivid, but keeping the relation with the original data. How would you do that</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8272705",
   "metadata": {},
   "source": [
    "<blockquote>To make the colors more vivid while maintaining the original relationships between the channels, you could normalize the mean signals by scaling them to a range of 0 to 1, then amplify them by raising them to a power less than 1 (such as \n",
    "x^ 0.5 for square root). This will enhance the lower values more than the higher ones, making the colors appear more vivid without altering the relationships.\n",
    "\n",
    "Here's how it's done:\n",
    "\n",
    "Normalize the mean signals for each channel by dividing them by the maximum value across all channels.\n",
    "Amplify the normalized signals by raising them to a power less than 1.\n",
    "Let's implement this adjustment.\n",
    "\n",
    "Adjusted Colors for More Vivid Display\n",
    "3D Scatter Plot:\n",
    "\n",
    "The 3D scatter plot now shows the amplified signals in the Red, Green, and Blue channels for each of the 5 largest objects. Each point is colored based on its amplified signal in each channel, making the colors more vivid.\n",
    "Amplified Signals:\n",
    "\n",
    "Red Channel: \n",
    "[\n",
    "1.0\n",
    ",\n",
    "0.82\n",
    ",\n",
    "0.92\n",
    ",\n",
    "0.78\n",
    ",\n",
    "0.57\n",
    "]\n",
    "[1.0,0.82,0.92,0.78,0.57]\n",
    "Green Channel: \n",
    "[\n",
    "0.70\n",
    ",\n",
    "0.94\n",
    ",\n",
    "0.94\n",
    ",\n",
    "0.41\n",
    ",\n",
    "0.57\n",
    "]\n",
    "[0.70,0.94,0.94,0.41,0.57]\n",
    "Blue Channel: \n",
    "[\n",
    "0.64\n",
    ",\n",
    "0.45\n",
    ",\n",
    "0.48\n",
    ",\n",
    "0.35\n",
    ",\n",
    "0.38\n",
    "]\n",
    "[0.64,0.45,0.48,0.35,0.38]\n",
    "The colors are now more vivid, thanks to the amplification process, while still retaining the original relationships between the channels.\n",
    "\n",
    "Would you like to proceed to the final step, creating a ternary plot of their brightnesses?\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9335d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum value across all channels and all objects to normalize\n",
    "max_value = max(max(mean_signals_r), max(mean_signals_g), max(mean_signals_b))\n",
    "\n",
    "# Normalize the mean signals\n",
    "normalized_r = [x / max_value for x in mean_signals_r]\n",
    "normalized_g = [x / max_value for x in mean_signals_g]\n",
    "normalized_b = [x / max_value for x in mean_signals_b]\n",
    "\n",
    "# Amplify the normalized signals (using square root as an example)\n",
    "amplified_r = [x**0.5 for x in normalized_r]\n",
    "amplified_g = [x**0.5 for x in normalized_g]\n",
    "amplified_b = [x**0.5 for x in normalized_b]\n",
    "\n",
    "# Plot the amplified signals in a 3D scatter plot again\n",
    "fig = plt.figure(figsize=(9, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Set color based on the amplified signal for each channel\n",
    "vivid_colors = [(r, g, b) for r, g, b in zip(amplified_r, amplified_g, amplified_b)]\n",
    "\n",
    "# Plot each point\n",
    "for r, g, b, color in zip(amplified_r, amplified_g, amplified_b, vivid_colors):\n",
    "    ax.scatter(r, g, b, c=[color], s=100)\n",
    "\n",
    "# Labeling and grid\n",
    "ax.set_xlabel('Amplified Signal in Red Channel')\n",
    "ax.set_ylabel('Amplified Signal in Green Channel')\n",
    "ax.set_zlabel('Amplified Signal in Blue Channel')\n",
    "ax.set_title('3D Scatter Plot of Amplified Signals')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Return the amplified signals for review\n",
    "amplified_r, amplified_g, amplified_b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ffc90",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: orange\">2.4 Not everything works in the sandbox\n",
    "</span></h3>\n",
    "\n",
    "<b>yes, move to step 4. Also, explain how a ternary plot works</b>\n",
    "\n",
    "<blockquote>Step 4: Ternary Plot of Brightnesses\n",
    "What is a Ternary Plot?\n",
    "A ternary plot is a triangular diagram used for plotting three-part compositions. Each vertex of the triangle represents a channel (in our case, Red, Green, and Blue). A point within the triangle shows the proportion of each channel in a specific object, and the closer a point is to a vertex, the higher the contribution of that channel to the object's overall color.\n",
    "\n",
    "In a ternary plot, the sum of the proportions for each point always equals 1. The position of a point within the triangle depends on the proportions of each channel, giving a visual representation of the color composition of each object.\n",
    "\n",
    "How to Read a Ternary Plot?\n",
    "Vertices: The three vertices of the triangle represent the three channels (Red, Green, Blue).\n",
    "Proximity: A point closer to a vertex indicates a higher proportion of that particular channel.\n",
    "Balance: Points located closer to the center represent a more balanced contribution from all three channels.\n",
    "Now, let's create a ternary plot for the 5 largest objects based on their amplified brightnesses in each channel.</blockquote>\n",
    "\n",
    "<i>>> AN error occured</i>\n",
    "\n",
    "<blockquote>I apologize for the inconvenience. It looks like the ternary plotting library is not available in this environment. However, you can easily install it in your own Jupyter Notebook by running !pip install python-ternary.\n",
    "\n",
    "Would you like to proceed with a code snippet that you can run in your own environment to generate the ternary plot?</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-ternary\n",
    "import ternary\n",
    "\n",
    "# Calculate the sum of the amplified signals for each object\n",
    "sum_amplified = [r + g + b for r, g, b in zip(amplified_r, amplified_g, amplified_b)]\n",
    "\n",
    "# Normalize the amplified signals so that they sum to 1 for each object (required for ternary plot)\n",
    "ternary_data = [(r/total, g/total, b/total) for r, g, b, total in zip(amplified_r, amplified_g, amplified_b, sum_amplified)]\n",
    "\n",
    "# Create the ternary plot\n",
    "fig, tax = ternary.figure(scale=1.0)\n",
    "tax.boundary(linewidth=1.0)\n",
    "tax.gridlines(multiple=0.1, color=\"blue\")\n",
    "\n",
    "# Set the labels and title\n",
    "tax.set_title(\"Ternary Plot of Brightnesses\", fontsize=16)\n",
    "tax.left_axis_label(\"Red\", fontsize=12)\n",
    "tax.right_axis_label(\"Green\", fontsize=12)\n",
    "tax.bottom_axis_label(\"Blue\", fontsize=12)\n",
    "\n",
    "# Plot the data points\n",
    "tax.scatter(ternary_data, marker='o', color=vivid_colors, s=100)\n",
    "\n",
    "# Show the plot\n",
    "tax.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aec0eb",
   "metadata": {},
   "source": [
    "<b>you may have to find another way or do your own implementation\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd011f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert ternary coordinates to Cartesian coordinates\n",
    "def ternary_to_cartesian(a, b, c):\n",
    "    x = 0.5 * (2.0 * b + c) / (a + b + c)\n",
    "    y = (3 ** 0.5) * 0.5 * c / (a + b + c)\n",
    "    return x, y\n",
    "\n",
    "# Convert the normalized ternary data to Cartesian coordinates\n",
    "cartesian_coords = [ternary_to_cartesian(r, g, b) for r, g, b in ternary_data]\n",
    "\n",
    "# Recalculate the sum of the amplified signals for each object\n",
    "sum_amplified = [r + g + b for r, g, b in zip(amplified_r, amplified_g, amplified_b)]\n",
    "\n",
    "# Normalize the amplified signals so that they sum to 1 for each object (required for ternary plot)\n",
    "ternary_data = [(r/total, g/total, b/total) for r, g, b, total in zip(amplified_r, amplified_g, amplified_b, sum_amplified)]\n",
    "\n",
    "# Convert the normalized ternary data to Cartesian coordinates\n",
    "cartesian_coords = [ternary_to_cartesian(r, g, b) for r, g, b in ternary_data]\n",
    "\n",
    "# Create the ternary plot using Matplotlib\n",
    "fig, ax = plt.subplots(figsize=(9, 8))\n",
    "\n",
    "# Draw the triangle\n",
    "triangle_x = [0, 1, 0.5, 0]\n",
    "triangle_y = [0, 0, (3 ** 0.5) * 0.5, 0]\n",
    "plt.plot(triangle_x, triangle_y, 'b-')\n",
    "\n",
    "# Label the vertices\n",
    "plt.text(-0.05, -0.05, 'R', fontsize=14)\n",
    "plt.text(1.01, -0.05, 'G', fontsize=14)\n",
    "plt.text(0.48, (3 ** 0.5) * 0.5 + 0.01, 'B', fontsize=14)\n",
    "\n",
    "# Plot the data points\n",
    "for (x, y), color in zip(cartesian_coords, vivid_colors):\n",
    "    plt.scatter(x, y, c=[color], s=100)\n",
    "\n",
    "# Adjust plot appearance\n",
    "plt.axis('off')\n",
    "plt.axis('equal')\n",
    "plt.title('Ternary Plot of Brightnesses')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c541d7",
   "metadata": {},
   "source": [
    "<h2><span style=\"color: orange\">3. Load excel data and fitting traces</span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cdc239",
   "metadata": {},
   "source": [
    "<h2><span style=\"color: orange\">3.1 Loading and parsing input files\n",
    "</span></h2>\n",
    "\n",
    "<b>Here is an excel spreadsheet where each column is are fluorescen data recorded from different cells.\n",
    "<b>First I want you to extract the data for each cell and plot them in light transparent gray</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b428d2c3",
   "metadata": {},
   "source": [
    "<blockquote>It looks like the output was truncated, but from what I can see, it appears that the data is separated by semicolons rather than commas. I'll go ahead and read the data again using the correct delimiter and then proceed with plotting the data for each cell in light transparent gray.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e84998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# File path to the CSV file\n",
    "file_path = 'KO_all.csv'\n",
    "\n",
    "# Read the CSV file with the correct delimiter\n",
    "df = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# Display the first few rows to confirm the structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad9ac62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting the data for each cell in light transparent gray\n",
    "plt.figure(figsize=(9, 8))\n",
    "\n",
    "# Extracting Time for x-axis\n",
    "time = df['Time']\n",
    "\n",
    "# Loop through each cell column to plot\n",
    "for column in df.columns[1:]:\n",
    "    plt.plot(time, df[column], color='gray', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Fluorescence Intensity')\n",
    "plt.title('Fluorescence Data for Different Cells')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca8c39",
   "metadata": {},
   "source": [
    "<blockquote>Here's the plot of the fluorescence data for each cell. Each trace is plotted in light transparent gray, allowing you to observe the overall trends and variations in the data. Would you like to proceed with any further analysis or visualization?</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dda649",
   "metadata": {},
   "source": [
    "<b>Now fit each cell with decaying mono or bi exponential and tell me what is the best fitting model</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdc9963",
   "metadata": {},
   "source": [
    "<blockquote>To fit each cell's fluorescence data to either a mono-exponential or bi-exponential decay model, I'll proceed as follows:\n",
    "\n",
    "Define the mono-exponential decay function: \n",
    "Define the bi-exponential decay function: \n",
    "\n",
    "Use non-linear curve fitting to fit each cell's data to both models.\n",
    "Compare the goodness-of-fit for each model using the sum of squared residuals or another criterion like the Akaike Information Criterion (AIC).\n",
    "Let's start by defining the decay functions and then proceed with the fitting.\n",
    "\n",
    "Finished working\n",
    "Show work\n",
    "It looks like the curve fitting for the bi-exponential model failed for at least one cell, likely due to the optimization not converging within the default number of iterations. This can happen for various reasons, such as poor initial parameter guesses or the complexity of the model.\n",
    "\n",
    "To resolve this, I can try the following approaches:\n",
    "\n",
    "Increase the maximum number of function evaluations (maxfev) for the curve fitting.\n",
    "Use a more robust optimization method if available.\n",
    "Would you like to proceed with these modifications?</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c3d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# File path to the CSV file\n",
    "file_path = 'C:/Users/Antoine.Valera/Desktop/KO_all.csv'\n",
    "\n",
    "# Read the CSV file with the correct delimiter\n",
    "df = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# Define the mono-exponential decay function\n",
    "def mono_exp(t, A, k):\n",
    "    return A * np.exp(-k * t)\n",
    "\n",
    "# Define the bi-exponential decay function\n",
    "def bi_exp(t, A1, k1, A2, k2):\n",
    "    return A1 * np.exp(-k1 * t) + A2 * np.exp(-k2 * t)\n",
    "\n",
    "# Initialize dictionaries to store fitting results and problematic cells\n",
    "best_fit_params_mono_resilient = {}\n",
    "best_fit_params_bi_resilient = {}\n",
    "best_fit_model_resilient = {}\n",
    "problematic_cells = []\n",
    "\n",
    "# Extract Time for x-axis\n",
    "time = df['Time']\n",
    "\n",
    "# Loop through each cell column to fit the data\n",
    "for column in df.columns[1:]:\n",
    "    y_data = df[column].values\n",
    "    x_data = time.values\n",
    "    \n",
    "    try:\n",
    "        # Fit to mono-exponential decay model with constraints\n",
    "        popt_mono, _ = curve_fit(mono_exp, x_data, y_data, p0=[1, 0.1], bounds=([0, 0], [1, np.inf]), maxfev=5000)\n",
    "        residuals_mono = y_data - mono_exp(x_data, *popt_mono)\n",
    "        ss_res_mono = np.sum(residuals_mono**2)\n",
    "        \n",
    "        # Fit to bi-exponential decay model with constraints\n",
    "        popt_bi, _ = curve_fit(bi_exp, x_data, y_data, p0=[1, 0.1, 0.5, 0.05], bounds=([0, 0, 0, 0], [1, np.inf, 1, np.inf]), maxfev=5000)\n",
    "        residuals_bi = y_data - bi_exp(x_data, *popt_bi)\n",
    "        ss_res_bi = np.sum(residuals_bi**2)\n",
    "        \n",
    "        # Store the parameters\n",
    "        best_fit_params_mono_resilient[column] = popt_mono\n",
    "        best_fit_params_bi_resilient[column] = popt_bi\n",
    "        \n",
    "        # Determine the best fitting model based on the sum of squared residuals\n",
    "        if ss_res_mono < ss_res_bi:\n",
    "            best_fit_model_resilient[column] = 'Mono-Exponential'\n",
    "        else:\n",
    "            best_fit_model_resilient[column] = 'Bi-Exponential'\n",
    "            \n",
    "    except Exception as e:\n",
    "        problematic_cells.append(column)\n",
    "\n",
    "# Function to calculate tau value from rate constant k\n",
    "def calculate_tau(k):\n",
    "    return 1 / k\n",
    "\n",
    "# Select 4 cells for visualization\n",
    "selected_cells = ['KO_001', 'KO_002', 'KO_003', 'KO_009']\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(9, 10))\n",
    "axs = axs.ravel()\n",
    "\n",
    "# Loop through selected cells to plot data and fit\n",
    "for i, cell in enumerate(selected_cells):\n",
    "    y_data = df[cell].values\n",
    "    x_data = time.values\n",
    "    axs[i].plot(x_data, y_data, color='gray', alpha=0.5, label='Data')\n",
    "    \n",
    "    best_model = best_fit_model_resilient[cell]\n",
    "    if best_model == 'Mono-Exponential':\n",
    "        popt = best_fit_params_mono_resilient[cell]\n",
    "        fit_data = mono_exp(x_data, *popt)\n",
    "        tau = calculate_tau(popt[1])\n",
    "        tau_text = f\"Tau: {tau:.3f}\"\n",
    "    else:\n",
    "        popt = best_fit_params_bi_resilient[cell]\n",
    "        fit_data = bi_exp(x_data, *popt)\n",
    "        tau1 = calculate_tau(popt[1])\n",
    "        tau2 = calculate_tau(popt[3])\n",
    "        tau_text = f\"Tau1: {tau1:.3f}\\nTau2: {tau2:.3f}\"\n",
    "        \n",
    "    axs[i].plot(x_data, fit_data, color='red', label='Fit')\n",
    "    axs[i].text(0.7 * x_data[-1], 0.2 * max(y_data), tau_text, fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "    axs[i].set_title(f'Cell: {cell} ({best_model})')\n",
    "    axs[i].set_xlabel('Time')\n",
    "    axs[i].set_ylabel('Fluorescence Intensity')\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if problematic_cells:\n",
    "    plt.figure()\n",
    "    for cell in problematic_cells:\n",
    "        plt.plot(time, df[cell], label=cell, alpha=0.7)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Fluorescence Intensity')\n",
    "    plt.title('Problematic Cells')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No problematic cells found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ac5558",
   "metadata": {},
   "source": [
    "<h2><span style=\"color: orange\">4. Spike Sorting</span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dda075",
   "metadata": {},
   "source": [
    "<b>Here is a csv file with four neurons being recorded at 20 kHz. Please extract the data and plot  all 4 traces in the same figure.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2f432",
   "metadata": {},
   "source": [
    "> Here is the plot showing the traces of all four neurons, recorded at a 20 kHz sampling rate. Each trace is labeled according to its corresponding channel. You can adjust the plot parameters as needed for your specific application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada17681",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# File path to the uploaded CSV file\n",
    "file_path = 'extracellular_signals_20kHz_20s_4chan.csv'\n",
    "\n",
    "# Reading the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Displaying the first few rows of the DataFrame to understand its structure\n",
    "df.head()\n",
    "\n",
    "# Plotting all four neuron traces on the same figure\n",
    "plt.figure()\n",
    "\n",
    "# Sampling rate and time vector for plotting\n",
    "fs = 20000  # 20 kHz\n",
    "time_vector = df.index / fs  # Convert index to time in seconds\n",
    "\n",
    "# Plotting each channel\n",
    "for col in df.columns[1:]:\n",
    "    plt.plot(time_vector, df[col], label=f'Channel {col}')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Neuron Traces at 20 kHz')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c280a4",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: orange\">4.1 Mixing instruction and general knowledge\n",
    "</span></h3>\n",
    "\n",
    "But you should still check the Mat & Met"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1fe43d",
   "metadata": {},
   "source": [
    "<b>There are some slow oscillations of large amplitude masking fast action potentials. This is due to movement aretfacts and LFP. Can you filter the traces using the most appropriate values and method</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb79d08",
   "metadata": {},
   "source": [
    "<blockquote>The plot shows both the original and filtered traces for all four neurons. For the filtering, a bandpass filter with a low cutoff frequency of 300 Hz and a high cutoff frequency of 3000 Hz was applied. This range is commonly used to isolate action potentials in neuronal recordings, effectively removing low-frequency artifacts like LFP (Local Field Potentials) and high-frequency noise.\n",
    "\n",
    "As you can see, the filtered traces appear to be free from the slow oscillations, highlighting the fast action potentials. You can adjust the filter parameters as needed for your specific application.</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d9d4b0",
   "metadata": {},
   "source": [
    "<b>Can you detect and extract action potentials on each channels. \n",
    "- Run a peak detection first. find the most appropriate threshold. These are extracellular recordings, so they may be overlapping populations of action potential. We'll try to seperate them later on. Then plot all traces in separate subplot, and indicatre with a red filled scatter the location of each detected event\n",
    "- then cut a window of 1.5ms before and after each event.\n",
    "- then do a PCA on the extracted bits and show me the an interactive 3d plot of PC1, PC2 and PC3</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26456f86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing the signal processing library from scipy\n",
    "from scipy import signal\n",
    "\n",
    "# Function to apply bandpass filter to a signal\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    \"\"\"\n",
    "    Bandpass filter the data between lowcut and highcut frequencies.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: The data to be filtered\n",
    "    - lowcut: The lower cutoff frequency\n",
    "    - highcut: The upper cutoff frequency\n",
    "    - fs: The sampling rate\n",
    "    - order: The order of the filter\n",
    "    \n",
    "    Returns:\n",
    "    - The filtered data\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "# Define bandpass filter parameters\n",
    "lowcut = 300.0  # Low cutoff frequency (Hz)\n",
    "highcut = 3000.0  # High cutoff frequency (Hz)\n",
    "order = 6  # Filter order\n",
    "\n",
    "# Apply the bandpass filter to each channel and store in a new DataFrame\n",
    "df_filtered = pd.DataFrame()\n",
    "for col in df.columns[1:]:\n",
    "    df_filtered[col] = bandpass_filter(df[col], lowcut, highcut, fs, order)\n",
    "\n",
    "# Plot the original and filtered traces\n",
    "plt.figure()\n",
    "for col in df.columns[1:]:\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(time_vector, df[col], label=f'Original {col}')\n",
    "    plt.title('Original Neuron Traces')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(time_vector, df_filtered[col], label=f'Filtered {col}')\n",
    "    plt.title('Filtered Neuron Traces')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce73b737",
   "metadata": {},
   "source": [
    "<blockquote>Here's a summary of the analyses performed:\n",
    "\n",
    "Peak Detection: Peaks were detected in the filtered traces of each channel using a threshold set to four times the standard deviation of the signal. The detected peaks are marked with red dots in the time-series plots for each channel.\n",
    "\n",
    "Window Extraction: For each detected peak, a window of 1.5 ms before and after the peak was extracted.\n",
    "\n",
    "PCA Analysis: Principal Component Analysis (PCA) was applied to the extracted windows, and the first three principal components (PC1, PC2, and PC3) were calculated for each channel.\n",
    "\n",
    "3D Plots: Interactive 3D plots show the distribution of the action potentials in the space defined by the first three principal components for each channel.\n",
    "\n",
    "You can interact with the 3D plots to better visualize the cluster patterns. These clusters may represent different types or populations of action potentials. Further analyses can be performed based on these PCA results to segregate or classify these potential types.</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa5d897",
   "metadata": {},
   "source": [
    "<b>Can you detect and extract action potentials on each channels. \n",
    "- Run a peak detection first. find the most appropriate threshold. These are extracellular recordings, so they may be overlapping populations of action potential. We'll try to seperate them later on. Then plot all traces in separate subplot, and indicatre with a red filled scatter the location of each detected event\n",
    "- then cut a window of 1.5ms before and after each event.\n",
    "- then do a PCA on the extracted bits and show me the an interactive 3d plot of PC1, PC2 and PC3 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1dbf7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importing additional libraries for peak detection and PCA\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# It appears there was an AttributeError because the 'signal' variable in the function had the same name as the imported 'signal' module.\n",
    "# Let's correct that and try again.\n",
    "\n",
    "# Function to detect peaks based on a threshold\n",
    "def detect_peaks(signal_data, threshold):\n",
    "    \"\"\"\n",
    "    Detect peaks that are greater than a given threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    - signal_data: The signal in which to find peaks\n",
    "    - threshold: The threshold for peak detection\n",
    "    \n",
    "    Returns:\n",
    "    - The indices of the peaks in the signal\n",
    "    \"\"\"\n",
    "    # Find peaks using scipy's find_peaks function\n",
    "    peaks, _ = signal.find_peaks(signal_data, height=threshold)\n",
    "    return peaks\n",
    "\n",
    "\n",
    "# Function to extract windows around peaks\n",
    "def extract_windows(signal, peaks, window_size, fs):\n",
    "    \"\"\"\n",
    "    Extract windows of a certain size around each peak.\n",
    "    \n",
    "    Parameters:\n",
    "    - signal: The signal from which to extract windows\n",
    "    - peaks: The indices of the peaks around which to extract windows\n",
    "    - window_size: The size of the window in milliseconds\n",
    "    - fs: The sampling rate of the signal\n",
    "    \n",
    "    Returns:\n",
    "    - A 2D NumPy array where each row is a window around a peak\n",
    "    \"\"\"\n",
    "    # Calculate the number of samples for the window size\n",
    "    samples_per_window = int(window_size * fs / 1000)\n",
    "    \n",
    "    # Initialize an array to store the windows\n",
    "    windows = np.zeros((len(peaks), 2 * samples_per_window))\n",
    "    \n",
    "    # Extract windows\n",
    "    for i, peak in enumerate(peaks):\n",
    "        if peak - samples_per_window >= 0 and peak + samples_per_window < len(signal):\n",
    "            windows[i, :] = signal[peak - samples_per_window:peak + samples_per_window]\n",
    "            \n",
    "    return windows\n",
    "\n",
    "# Parameters for peak detection and window extraction\n",
    "threshold_multiplier = 4  # Multiplier for setting threshold based on standard deviation\n",
    "window_size = 1.5  # Window size in milliseconds\n",
    "\n",
    "# Initialize a dictionary to store peak indices and extracted windows for each channel\n",
    "peaks_dict = {}\n",
    "windows_dict = {}\n",
    "\n",
    "# Run peak detection and window extraction for each channel again\n",
    "plt.figure()\n",
    "for i, col in enumerate(df_filtered.columns):\n",
    "    # Calculate the threshold for peak detection based on the standard deviation of the filtered signal\n",
    "    threshold = threshold_multiplier * np.std(df_filtered[col])\n",
    "    \n",
    "    # Detect peaks\n",
    "    peaks = detect_peaks(df_filtered[col], threshold)\n",
    "    peaks_dict[col] = peaks\n",
    "    \n",
    "    # Extract windows around peaks\n",
    "    windows = extract_windows(df_filtered[col].to_numpy(), peaks, window_size, fs)\n",
    "    windows_dict[col] = windows\n",
    "    \n",
    "    # Plot the filtered signal and detected peaks\n",
    "    plt.subplot(4, 1, i+1)\n",
    "    plt.plot(time_vector, df_filtered[col], label=f'Filtered {col}')\n",
    "    plt.scatter(time_vector[peaks], df_filtered[col][peaks], color='red')\n",
    "    plt.title(f'Channel {col} with Detected Peaks')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f579d",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: orange\">4.2 Interrupt, Interact, ask for Options\n",
    "</span></h3>\n",
    "\n",
    "<b>let's come back brielfy to the detection code. It misses a lot of stuff and catches alot of noise. Can we use something more robust </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc8e61",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "    Certainly, a more robust approach could involve a combination of thresholding methods, filtering, and other pre-processing steps to improve the accuracy of spike detection. A commonly used method for robust spike detection in extracellular recordings is the \"matched filter\" approach, where a template waveform is used to scan through the data and identify spikes.\n",
    "\n",
    "Here are some possible alternatives or enhancements to the threshold-based peak detection method:\n",
    "\n",
    "1. Median Absolute Deviation (MAD)\n",
    "Instead of using standard deviation for setting the threshold, you can use the Median Absolute Deviation (MAD), which is less sensitive to outliers.\n",
    "\n",
    "MAD Threshold\n",
    "\n",
    "2. Matched Filtering\n",
    "A template waveform (e.g., an average spike waveform) can be used to cross-correlate with the signal, enhancing the spike detection.\n",
    "\n",
    "3. Non-linear Energy Operator (NEO)\n",
    "A nonlinear transformation of the signal that is sensitive to the presence of spikes. The NEO of a signal \n",
    "x is given by NEO[n]=x[n] −x[n−1]×x[n+1].\n",
    "\n",
    "4. Wavelet Transform\n",
    "Wavelet-based methods can be used to decompose the signal into different frequency bands, making it easier to identify spikes.\n",
    "\n",
    "5. Refractory Period\n",
    "Incorporate a refractory period into the detection algorithm to avoid detecting multiple events that are too close to each other.\n",
    "\n",
    "Here's a sample Python code snippet for spike detection using the Median Absolute Deviation (MAD) method:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eaa814",
   "metadata": {},
   "source": [
    "<b>let's compare methods 2 and 3</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5acf889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import correlate\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "# Function for spike detection using Matched Filtering\n",
    "def detect_spikes_matched_filter(signal, template, threshold_multiplier=4):\n",
    "    # Cross-correlate the signal with the template\n",
    "    corr_signal = correlate(signal, template, mode='same')\n",
    "    \n",
    "    # Set the threshold for peak detection\n",
    "    threshold = threshold_multiplier * np.std(corr_signal)\n",
    "    \n",
    "    # Detect peaks\n",
    "    peaks, _ = find_peaks(corr_signal, height=threshold)\n",
    "    \n",
    "    return peaks, corr_signal\n",
    "\n",
    "# Function for spike detection using Non-linear Energy Operator (NEO)\n",
    "def detect_spikes_neo(signal, threshold_multiplier=2):\n",
    "    # Calculate the NEO\n",
    "    neo_signal = np.zeros_like(signal)\n",
    "    neo_signal[1:-1] = signal[1:-1]**2 - signal[:-2] * signal[2:]\n",
    "    \n",
    "    # Set the threshold for peak detection\n",
    "    threshold = threshold_multiplier * np.std(neo_signal)\n",
    "    \n",
    "    # Detect peaks\n",
    "    peaks, _ = find_peaks(neo_signal, height=threshold)\n",
    "    \n",
    "    return peaks, neo_signal\n",
    "\n",
    "# Create a synthetic spike template for matched filtering\n",
    "# A simple Gaussian function to serve as a synthetic spike template\n",
    "template_length = int(1.5 * fs / 1000)  # 1.5 ms\n",
    "x = np.linspace(-template_length / fs, template_length / fs, 2 * template_length)\n",
    "template = np.exp(-x**2 / (2 * (0.2 / 1000)**2))\n",
    "\n",
    "# Apply both methods to the filtered data for Channel 1\n",
    "signal = df_filtered['0'].to_numpy()\n",
    "peaks_mf, corr_signal = detect_spikes_matched_filter(signal, template)\n",
    "peaks_neo, neo_signal = detect_spikes_neo(signal)\n",
    "\n",
    "# Plotting the results for comparison\n",
    "fig, axes = plt.subplots(2, 1)\n",
    "\n",
    "# Matched Filtering\n",
    "axes[0].plot(corr_signal, label='Correlated Signal')\n",
    "axes[0].scatter(peaks_mf, corr_signal[peaks_mf], color='red', label='Detected Spikes')\n",
    "axes[0].set_title('Matched Filtering')\n",
    "axes[0].legend()\n",
    "\n",
    "# Non-linear Energy Operator (NEO)\n",
    "axes[1].plot(neo_signal, label='NEO Signal')\n",
    "axes[1].scatter(peaks_neo, neo_signal[peaks_neo], color='red', label='Detected Spikes')\n",
    "axes[1].set_title('Non-linear Energy Operator (NEO)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4730bd54",
   "metadata": {},
   "source": [
    "<span style=\"color: orange\"><b>I liked Peaks neo, so let's set that as a variable. I also manually changed the code in the notebook. This will create a mismatch between you GPT promp and here</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68538cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = peaks_neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2989654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df_filtered['0'] is your bandpass-filtered signal for Channel 1\n",
    "# and peaks_neo are the detected peaks using NEO\n",
    "\n",
    "# Plotting the bandpass-filtered trace\n",
    "plt.figure()\n",
    "plt.plot(df_filtered['0'], label='Bandpass Filtered Signal', color='darkgrey')\n",
    "\n",
    "# Plotting the detected events\n",
    "plt.scatter(peaks, df_filtered['0'].iloc[peaks], color='red', label='Detected Events (NEO)', zorder=5)\n",
    "\n",
    "plt.title('Detected Events on Bandpass Filtered Trace for Channel 1')\n",
    "plt.xlabel('Time (samples)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Initialize a dictionary to store peak indices and extracted windows for each channel\n",
    "peaks_dict = {}\n",
    "windows_dict = {}\n",
    "\n",
    "# Run peak detection and window extraction for each channel again\n",
    "plt.figure()\n",
    "for i, col in enumerate(df_filtered.columns):\n",
    "    \n",
    "    # Detect peaks\n",
    "    peaks_dict[col] = peaks\n",
    "    \n",
    "    # Extract windows around peaks\n",
    "    windows = extract_windows(df_filtered[col].to_numpy(), peaks, window_size, fs)\n",
    "    windows_dict[col] = windows\n",
    "    \n",
    "    # Plot the filtered signal and detected peaks\n",
    "    plt.subplot(4, 1, i+1)\n",
    "    plt.plot(time_vector, df_filtered[col], label=f'Filtered {col}')\n",
    "    plt.scatter(time_vector[peaks], df_filtered[col][peaks], color='red')\n",
    "    plt.title(f'Channel {col} with Detected Peaks')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ac332",
   "metadata": {},
   "source": [
    "<b>This detection is better, let's resume our processing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a63b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have detected peaks and extracted windows around them, let's perform PCA on these extracted windows.\n",
    "\n",
    "# Initialize PCA with 3 components\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "# Initialize a dictionary to store PCA results for each channel\n",
    "pca_results = {}\n",
    "\n",
    "# Perform PCA on the extracted windows for each channel\n",
    "for col, windows in windows_dict.items():\n",
    "    pca_results[col] = pca.fit_transform(windows)\n",
    "\n",
    "# Create an interactive 3D plot of the PCA results\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "for i, (col, pca_data) in enumerate(pca_results.items()):\n",
    "    ax = fig.add_subplot(2, 2, i+1, projection='3d')\n",
    "    ax.scatter(pca_data[:, 0], pca_data[:, 1], pca_data[:, 2], c='r', marker='o')\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_zlabel('PC3')\n",
    "    ax.set_title(f'PCA Results for Channel {col}')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d6467e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<b>can you plot the all detected traces for the extracted 3ms bits for each channel in very light gray (alpha 0.05) and then a thick black line for the average</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a61072c",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "The plots for each channel show all the extracted windows of 3 ms duration around each detected peak. These are plotted in light gray with a low alpha value (0.05) for visibility. The thick black line represents the average of all these extracted windows for each channel.\n",
    "\n",
    "This visualization allows you to see both the individual variability and the general trend of the action potentials detected in each channel. Feel free to adjust the parameters for further analysis.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d7c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot extracted windows and their average for each channel\n",
    "def plot_extracted_windows(windows, fs, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Plot all extracted windows in light gray and their average in black.\n",
    "    \n",
    "    Parameters:\n",
    "    - windows: 2D array of extracted windows\n",
    "    - fs: Sampling rate\n",
    "    - alpha: Transparency for individual traces\n",
    "    \n",
    "    Returns:\n",
    "    - A plot showing all extracted windows and their average\n",
    "    \"\"\"\n",
    "    # Create a time vector for the windows\n",
    "    num_samples = windows.shape[1]\n",
    "    time_vector = np.linspace(-1.5, 1.5, num_samples)  # Window is 3 ms wide centered at the peak, so -1.5 to 1.5 ms\n",
    "    \n",
    "    # Plot each window in light gray\n",
    "    for window in windows:\n",
    "        plt.plot(time_vector, window, color='gray', alpha=alpha)\n",
    "    \n",
    "    # Plot the average window in black\n",
    "    average_window = np.mean(windows, axis=0)\n",
    "    plt.plot(time_vector, average_window, color='black', linewidth=2)\n",
    "\n",
    "# Create plots for each channel\n",
    "plt.figure()\n",
    "for i, (col, windows) in enumerate(windows_dict.items()):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plot_extracted_windows(windows, fs)\n",
    "    plt.title(f'Extracted Windows and Average for Channel {col}')\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e92c593",
   "metadata": {},
   "source": [
    "<b> There seem to be 2 profiles on channel 1. Can you seperate them out using kmeans clustering on PCA. Show also the clusters in  PC1, PC2 PC3 3d plot with color code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de39905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing KMeans clustering from sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Perform KMeans clustering on PCA results of channel 1\n",
    "channel = '0'\n",
    "pca_data_channel_1 = pca_results[channel]\n",
    "\n",
    "# Assuming 2 clusters based on observation\n",
    "n_clusters = 2\n",
    "\n",
    "# Re-run KMeans clustering on PCA results for channel 1\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(pca_data_channel_1)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Plotting the clusters in the PCA 3D space\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i in range(n_clusters):\n",
    "    cluster_data = pca_data_channel_1[labels == i]\n",
    "    ax.scatter(cluster_data[:, 0], cluster_data[:, 1], cluster_data[:, 2], label=f'Cluster {i+1}')\n",
    "\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "ax.set_title('KMeans Clusters in PCA Space for Channel 1')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25829b1",
   "metadata": {},
   "source": [
    "<b>What would be alternative dimensionality reduction and clustering approaches that could yield better results for this type of data (spikesorting)?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb6e2b3",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "Spike sorting often involves complex data with overlapping signals from multiple neurons, noise, and other artifacts. While PCA and KMeans are widely used and computationally efficient, they might not always capture the complexity of the data. Here are some alternative dimensionality reduction and clustering methods that are often used in the context of spike sorting:\n",
    "\n",
    "Dimensionality Reduction:\n",
    "t-SNE (t-Distributed Stochastic Neighbor Embedding): Effective for capturing non-linear relationships, but computationally more intensive than PCA.\n",
    "\n",
    "UMAP (Uniform Manifold Approximation and Projection): Similar to t-SNE but faster and more scalable.\n",
    "\n",
    "ICA (Independent Component Analysis): Useful when the source signals are statistically independent, which might be the case for spikes from different neurons.\n",
    "\n",
    "Autoencoders: Neural networks can be trained to reduce dimensionality in a way that captures complex, non-linear relationships in the data.\n",
    "\n",
    "Clustering Approaches:\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise): Does not assume that clusters are spherical and can find arbitrarily shaped clusters. Also, it doesn't require specifying the number of clusters beforehand.\n",
    "\n",
    "GMM (Gaussian Mixture Model): Assumes that data is generated from a mixture of several Gaussian distributions. More flexible than KMeans in terms of cluster covariance.\n",
    "\n",
    "Agglomerative Hierarchical Clustering: Builds a tree of clusters. Useful for understanding the hierarchical structure of the data.\n",
    "\n",
    "OPTICS (Ordering Points To Identify the Clustering Structure): Similar to DBSCAN, but allows for varying density clusters.\n",
    "\n",
    "Mean Shift Clustering: Does not assume any prior knowledge on the number of clusters and can find arbitrarily shaped clusters.\n",
    "\n",
    "HDBSCAN (Hierarchical DBSCAN): An extension of DBSCAN that doesn't require a distance parameter to be set.\n",
    "\n",
    "Hybrid Approaches:\n",
    "Template Matching: After dimensionality reduction and initial clustering, template waveforms can be generated and used to refine the sorting.\n",
    "\n",
    "Bayesian Approaches: Utilize prior knowledge about the spiking activity or the statistical properties of the spikes for both dimensionality reduction and clustering.\n",
    "\n",
    "Supervised Learning: If labeled data is available, supervised classifiers can be trained to sort spikes.\n",
    "\n",
    "Spike Forest: An automated spike sorting framework that combines multiple algorithms to provide a consensus result.\n",
    "\n",
    "Choosing the best method depends on the specifics of the data and what questions you are trying to answer. Often, a combination of methods is used in a pipeline to achieve the best results.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623712c",
   "metadata": {},
   "source": [
    "<b>Let's try an ICA, followed by HDBSCAN </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59261d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-importing the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import FastICA\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "# Function to apply bandpass filter to a signal\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "# Function to detect peaks based on a threshold\n",
    "def detect_peaks(signal_data, threshold):\n",
    "    peaks, _ = signal.find_peaks(signal_data, height=threshold)\n",
    "    return peaks\n",
    "\n",
    "# Function to extract windows around peaks\n",
    "def extract_windows(signal, peaks, window_size, fs):\n",
    "    samples_per_window = int(window_size * fs / 1000)\n",
    "    windows = np.zeros((len(peaks), 2 * samples_per_window))\n",
    "    for i, peak in enumerate(peaks):\n",
    "        if peak - samples_per_window >= 0 and peak + samples_per_window < len(signal):\n",
    "            windows[i, :] = signal[peak - samples_per_window:peak + samples_per_window]\n",
    "    return windows\n",
    "\n",
    "# Perform Independent Component Analysis (ICA) on the extracted windows for channel 1\n",
    "ica = FastICA(n_components=3, random_state=0)\n",
    "ica_data_channel_1 = ica.fit_transform(windows_dict['0'])\n",
    "\n",
    "# Plotting the data points in the ICA 3D space\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(ica_data_channel_1[:, 0], ica_data_channel_1[:, 1], ica_data_channel_1[:, 2])\n",
    "\n",
    "ax.set_xlabel('IC1')\n",
    "ax.set_ylabel('IC2')\n",
    "ax.set_zlabel('IC3')\n",
    "ax.set_title('Data Points in ICA Space for Channel 1')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523de916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing t-SNE for dimensionality reduction\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Perform t-SNE dimensionality reduction on the extracted windows for channel 1\n",
    "# Setting random_state for reproducibility\n",
    "tsne_model = TSNE(n_components=3, random_state=0, perplexity=30, n_iter=1000)\n",
    "tsne_data_channel_1 = tsne_model.fit_transform(windows_dict['0'])\n",
    "\n",
    "# Plotting the data points in the t-SNE 3D space\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(tsne_data_channel_1[:, 0], tsne_data_channel_1[:, 1], tsne_data_channel_1[:, 2])\n",
    "\n",
    "ax.set_xlabel('t-SNE1')\n",
    "ax.set_ylabel('t-SNE2')\n",
    "ax.set_zlabel('t-SNE3')\n",
    "ax.set_title('Data Points in t-SNE Space for Channel 1')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d26f4",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: orange\">4.4. Proceeding with missing tool box</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e21da0",
   "metadata": {},
   "source": [
    "<b>write a hdbscan code now\n",
    "</b>\n",
    "\n",
    "<blockquote>Certainly! While I can't run HDBSCAN here due to the environment limitations, I can provide you with the code snippet to perform HDBSCAN clustering on your local machine after performing t-SNE or any other dimensionality reduction. Here's how you can do it:</blockquote>\n",
    "    \n",
    "<b>OK, generate 2 figures. One figure have as many suplots as detected units. Each subplot has all the traces of their cluster in light gray (alpha 0.05) and a thick black mean trace (using the 3ms extracted traces).\n",
    "in the second figure, plot the filtered signal in dark grey, and identify the events using the color of their cluster (2 colors, 2 clusters for example) by adding ticks above each event. put the ticks from different units with a small offset</b>\n",
    "\n",
    "<blockquote>Certainly, you can generate these plots locally using the code snippets I'll provide. Given that HDBSCAN clustering and t-SNE are not directly runnable here, let's assume that you have the labels from HDBSCAN clustering in a variable named labels_hdbscan and the extracted 3ms windows in a variable named windows_dict['0'].\n",
    "\n",
    "Here's how you can generate the two figures:</blockquote>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hdbscan\n",
    "# Importing HDBSCAN\n",
    "import hdbscan\n",
    "\n",
    "# Perform HDBSCAN clustering on t-SNE results for channel 1\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=20)  # You can adjust the min_cluster_size parameter\n",
    "labels_hdbscan = clusterer.fit_predict(tsne_data_channel_1)  # Replace with your t-SNE or other reduced-dimension data\n",
    "\n",
    "# Plotting the clusters in the t-SNE 3D space\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "unique_labels = np.unique(labels_hdbscan)\n",
    "for label in unique_labels:\n",
    "    if label == -1:\n",
    "        # Noise points are labeled -1\n",
    "        continue\n",
    "    cluster_data = tsne_data_channel_1[labels_hdbscan == label]\n",
    "    ax.scatter(cluster_data[:, 0], cluster_data[:, 1], cluster_data[:, 2], label=f'Cluster {label+1}')\n",
    "\n",
    "ax.set_xlabel('t-SNE1')\n",
    "ax.set_ylabel('t-SNE2')\n",
    "ax.set_zlabel('t-SNE3')\n",
    "ax.set_title('HDBSCAN Clusters in t-SNE Space for Channel 1')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f00425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "unique_labels = np.unique(labels_hdbscan)\n",
    "fig1, axes = plt.subplots(len(unique_labels), 1, figsize=(9, 5 * len(unique_labels)))\n",
    "\n",
    "for idx, label in enumerate(unique_labels):\n",
    "    ax = axes[idx]\n",
    "    cluster_data = windows_dict['0'][labels_hdbscan == label]\n",
    "    for trace in cluster_data:\n",
    "        ax.plot(trace, color='gray', alpha=0.05)\n",
    "    mean_trace = np.mean(cluster_data, axis=0)\n",
    "    ax.plot(mean_trace, color='black', linewidth=2)\n",
    "    ax.set_title(f'Cluster {label+1}')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d96723",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax = plt.subplots()\n",
    "\n",
    "# Plotting the filtered signal\n",
    "ax.plot(df_filtered['0'], color='darkgray')\n",
    "\n",
    "# Adding ticks for each event\n",
    "offset = 0\n",
    "for label in unique_labels:\n",
    "    cluster_peaks = peaks_dict['0'][labels_hdbscan == label]\n",
    "    ax.scatter(cluster_peaks, [df_filtered['0'].iloc[peak] + offset for peak in cluster_peaks], label=f'Cluster {label+1}', s=50)\n",
    "    offset += 10  # Increment offset for better visualization\n",
    "\n",
    "ax.set_title('Filtered Signal with Identified Events')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef62c92",
   "metadata": {},
   "source": [
    "<h2><span style=\"color: orange\">5. Commenting Code</span>\n",
    "</h2>\n",
    "\n",
    "<b>Here is a code in cpp running from matlab. I am not very good with cpp.\n",
    "\n",
    "Can you explain what this code does in details.</b>\n",
    "```cpp\n",
    "\n",
    "void mexFunction(int nlhs, mxArray* plhs[], int nrhs, const mxArray* prhs[])\n",
    "{\n",
    "\tuint32_t func = *(uint32_t*)mxGetData(prhs[0]);\n",
    "\tplhs[0] = mxCreateNumericMatrix(1,1,mxINT32_CLASS,mxREAL);\n",
    "\tNiFpga_Status *status = (NiFpga_Status *)mxGetData(plhs[0]);\n",
    "\n",
    "\tswitch(func)\n",
    "\t{\n",
    "    case 5060: // start fifo thread\n",
    "\t{\n",
    "\t\tstop_threads = false;\n",
    "\n",
    "            ctx.session = *(NiFpga_Session*)mxGetData(prhs[1]);\n",
    "            ctx.nElem = *(uint32_t*)mxGetData(prhs[3]);\n",
    "            ctx.timeout = *(uint32_t*)mxGetData(prhs[4]);\n",
    "\n",
    "            for (int m = 0; m < 2; m++)\n",
    "            {\n",
    "                pipe_t* the_pipe = pipe_new(sizeof(uint32_t), PIPE_SIZE);\n",
    "                pipe_producer_t* prod = pipe_producer_new(the_pipe);\n",
    "                pipe_consumer_t* cons = pipe_consumer_new(the_pipe);\n",
    "                ctx.producer[m] = prod;\n",
    "                pipe_reader[m] = cons;\n",
    "                pipe_free(the_pipe);\n",
    "            }\n",
    "            pthread_create(&thread, NULL, &move_fifo_to_pipe, &ctx);\n",
    "\n",
    "\t\tbreak;\n",
    "\t}\n",
    "\n",
    "\tdefault:\n",
    "\t{\n",
    "\t\t*status = -1;\n",
    "\t\tbreak;\n",
    "\t}\n",
    "\t}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7bc825",
   "metadata": {},
   "source": [
    "<blockquote>Certainly! This is a C++ function that is designed to be called from MATLAB. Specifically, it is a MEX function, which is a type of function that allows you to call C/C++ code from MATLAB. Let's break down the code step-by-step.\n",
    "\n",
    "### Function Signature\n",
    "```cpp\n",
    "void mexFunction(int nlhs, mxArray* plhs[], int nrhs, const mxArray* prhs[])\n",
    "```\n",
    "- `nlhs`: Number of left-hand side (output) arguments.\n",
    "- `plhs[]`: Array of pointers to the output arguments.\n",
    "- `nrhs`: Number of right-hand side (input) arguments.\n",
    "- `prhs[]`: Array of pointers to the input arguments.\n",
    "\n",
    "### Variable Initialization\n",
    "```cpp\n",
    "uint32_t func = *(uint32_t*)mxGetData(prhs[0]);\n",
    "plhs[0] = mxCreateNumericMatrix(1,1,mxINT32_CLASS,mxREAL);\n",
    "NiFpga_Status *status = (NiFpga_Status *)mxGetData(plhs[0]);\n",
    "```\n",
    "- `func`: Extracts the first input argument (`prhs[0]`) and casts it to a 32-bit unsigned integer. This variable likely specifies what function or operation to perform.\n",
    "- `plhs[0]`: Creates a 1x1 MATLAB numeric matrix of type `mxINT32_CLASS` for the output.\n",
    "- `status`: A pointer to the output data, used to hold the status of the operation.\n",
    "\n",
    "### Switch Statement\n",
    "The main logic is contained within a `switch` statement that acts based on the value of `func`.\n",
    "\n",
    "#### Case 5060: Start FIFO Thread\n",
    "If `func` is 5060, it starts a First In, First Out (FIFO) thread for data transfer.\n",
    "\n",
    "```cpp\n",
    "ctx.session = *(NiFpga_Session*)mxGetData(prhs[1]);\n",
    "ctx.nElem = *(uint32_t*)mxGetData(prhs[3]);\n",
    "ctx.timeout = *(uint32_t*)mxGetData(prhs[4]);\n",
    "```\n",
    "- Initializes a context `ctx` with session information, the number of elements (`nElem`), and a timeout value, all coming from the input arguments.\n",
    "\n",
    "```cpp\n",
    "for (int m = 0; m < 2; m++)\n",
    "{\n",
    "    pipe_t* the_pipe = pipe_new(sizeof(uint32_t), PIPE_SIZE);\n",
    "    pipe_producer_t* prod = pipe_producer_new(the_pipe);\n",
    "    pipe_consumer_t* cons = pipe_consumer_new(the_pipe);\n",
    "    ctx.producer[m] = prod;\n",
    "    pipe_reader[m] = cons;\n",
    "    pipe_free(the_pipe);\n",
    "}\n",
    "```\n",
    "- Creates two new pipes (probably for data transfer) and associates producers and consumers with each pipe.\n",
    "- Stores the pipe producers and consumers in the context and a global variable.\n",
    "\n",
    "```cpp\n",
    "pthread_create(&thread, NULL, &move_fifo_to_pipe, &ctx);\n",
    "```\n",
    "- Creates a new POSIX thread that runs the function `move_fifo_to_pipe` with `ctx` as its argument.\n",
    "\n",
    "#### Default Case\n",
    "If `func` is not 5060, it sets the `status` to -1, indicating an error or unsupported operation.\n",
    "\n",
    "---\n",
    "\n",
    "I hope this clarifies what the code is doing. If you have more questions, feel free to ask!</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a31bee",
   "metadata": {},
   "source": [
    "<b>Can you reprint a version of the code with a lot of comments and debugging message (using mexprintf)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3a3483",
   "metadata": {},
   "source": [
    "```cpp\n",
    "\n",
    "#include \"mex.h\"\n",
    "#include \"NiFpga.h\"\n",
    "#include <pthread.h>\n",
    "\n",
    "// Declare any additional global variables or structs here\n",
    "// ...\n",
    "\n",
    "void mexFunction(int nlhs, mxArray* plhs[], int nrhs, const mxArray* prhs[])\n",
    "{\n",
    "    // Debugging message to indicate the function has been entered\n",
    "    mexPrintf(\"Entered mexFunction.\\n\");\n",
    "    \n",
    "    // Extract the first input argument and cast it to uint32_t\n",
    "    uint32_t func = *(uint32_t*)mxGetData(prhs[0]);\n",
    "    mexPrintf(\"Function code: %u\\n\", func);  // Debugging message for function code\n",
    "    \n",
    "    // Create a 1x1 mxArray to hold the output status\n",
    "    plhs[0] = mxCreateNumericMatrix(1,1,mxINT32_CLASS,mxREAL);\n",
    "    \n",
    "    // Get a pointer to the output status data\n",
    "    NiFpga_Status *status = (NiFpga_Status *)mxGetData(plhs[0]);\n",
    "\n",
    "    // Switch based on the function code\n",
    "    switch(func)\n",
    "    {\n",
    "        case 5060:  // Start FIFO thread\n",
    "            mexPrintf(\"Starting FIFO thread.\\n\");  // Debugging message\n",
    "            \n",
    "            // Initialize session, number of elements, and timeout from input arguments\n",
    "            ctx.session = *(NiFpga_Session*)mxGetData(prhs[1]);\n",
    "            ctx.nElem = *(uint32_t*)mxGetData(prhs[3]);\n",
    "            ctx.timeout = *(uint32_t*)mxGetData(prhs[4]);\n",
    "            \n",
    "            // Create pipes and associate producers and consumers\n",
    "            for (int m = 0; m < 2; m++)\n",
    "            {\n",
    "                mexPrintf(\"Creating pipe #%d.\\n\", m);  // Debugging message\n",
    "                \n",
    "                pipe_t* the_pipe = pipe_new(sizeof(uint32_t), PIPE_SIZE);\n",
    "                pipe_producer_t* prod = pipe_producer_new(the_pipe);\n",
    "                pipe_consumer_t* cons = pipe_consumer_new(the_pipe);\n",
    "                \n",
    "                ctx.producer[m] = prod;\n",
    "                pipe_reader[m] = cons;\n",
    "                \n",
    "                // Free the pipe (note: make sure this is the correct time to free it)\n",
    "                pipe_free(the_pipe);\n",
    "            }\n",
    "            \n",
    "            // Create the thread to move data from FIFO to pipe\n",
    "            pthread_create(&thread, NULL, &move_fifo_to_pipe, &ctx);\n",
    "            mexPrintf(\"FIFO thread created.\\n\");  // Debugging message\n",
    "            \n",
    "            break;\n",
    "\n",
    "        default:  // Unsupported function code\n",
    "            mexPrintf(\"Unsupported function code.\\n\");  // Debugging message\n",
    "            \n",
    "            // Set the status to -1\n",
    "            *status = -1;\n",
    "            \n",
    "            break;\n",
    "    }\n",
    "    \n",
    "    mexPrintf(\"Exiting mexFunction.\\n\");  // Debugging message to indicate the function is exiting\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce18ef28",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: orange\">5.2 Improve readability and code standards</span></h3>\n",
    "\n",
    "<b>Can you reprint the original version, but follow strictly the latest standard and good prctice in cpp.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d78c79a",
   "metadata": {},
   "source": [
    "<blockquote>Certainly! To modernize the code, I'll make a few changes:\n",
    "\n",
    "1. Use C++11 or later features, such as `nullptr` instead of `NULL`.\n",
    "2. Include necessary header files for clarity.\n",
    "3. Add `const` qualifiers where applicable for better safety.\n",
    "4. Use C++-style casts instead of C-style casts for better type safety.\n",
    "5. Add some error checks for input argument numbers (`nrhs` and `nlhs`).\n",
    "\n",
    "Here's the updated version:\n",
    "\n",
    "```cpp\n",
    "#include \"mex.h\"\n",
    "#include \"NiFpga.h\"\n",
    "#include <cstdint>\n",
    "#include <pthread.h>\n",
    "\n",
    "// Assuming the following are declared and defined elsewhere\n",
    "extern bool stop_threads;\n",
    "extern SomeType ctx;  // Replace SomeType with the actual type of ctx\n",
    "extern pthread_t thread;\n",
    "extern pipe_t* pipe_new(size_t, size_t);\n",
    "extern pipe_producer_t* pipe_producer_new(pipe_t*);\n",
    "extern pipe_consumer_t* pipe_consumer_new(pipe_t*);\n",
    "extern void pipe_free(pipe_t*);\n",
    "extern void* move_fifo_to_pipe(void*);\n",
    "extern const size_t PIPE_SIZE;\n",
    "\n",
    "void mexFunction(int nlhs, mxArray* plhs[], int nrhs, const mxArray* prhs[])\n",
    "{\n",
    "    // Check the number of input and output arguments\n",
    "    if (nrhs < 5) {\n",
    "        mexErrMsgIdAndTxt(\"MATLAB:mexFunction:invalidNumInputs\",\n",
    "                          \"At least 5 input arguments required.\");\n",
    "    }\n",
    "    if (nlhs > 1) {\n",
    "        mexErrMsgIdAndTxt(\"MATLAB:mexFunction:invalidNumOutputs\",\n",
    "                          \"Too many output arguments.\");\n",
    "    }\n",
    "\n",
    "    // Extract the first input argument\n",
    "    const uint32_t func = *reinterpret_cast<const uint32_t*>(mxGetData(prhs[0]));\n",
    "    plhs[0] = mxCreateNumericMatrix(1, 1, mxINT32_CLASS, mxREAL);\n",
    "    auto* status = reinterpret_cast<NiFpga_Status*>(mxGetData(plhs[0]));\n",
    "\n",
    "    switch (func) {\n",
    "        case 5060:  // Start FIFO thread\n",
    "            stop_threads = false;\n",
    "            ctx.session = *reinterpret_cast<const NiFpga_Session*>(mxGetData(prhs[1]));\n",
    "            ctx.nElem = *reinterpret_cast<const uint32_t*>(mxGetData(prhs[3]));\n",
    "            ctx.timeout = *reinterpret_cast<const uint32_t*>(mxGetData(prhs[4]));\n",
    "\n",
    "            for (int m = 0; m < 2; ++m) {\n",
    "                auto* the_pipe = pipe_new(sizeof(uint32_t), PIPE_SIZE);\n",
    "                auto* prod = pipe_producer_new(the_pipe);\n",
    "                auto* cons = pipe_consumer_new(the_pipe);\n",
    "                ctx.producer[m] = prod;\n",
    "                // Assuming pipe_reader is declared and defined elsewhere\n",
    "                pipe_reader[m] = cons;\n",
    "                pipe_free(the_pipe);\n",
    "            }\n",
    "            pthread_create(&thread, nullptr, &move_fifo_to_pipe, &ctx);\n",
    "            break;\n",
    "\n",
    "        default:\n",
    "            *status = -1;\n",
    "            break;\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Note that I've used placeholders like `SomeType` for types that aren't defined in the original code. You would replace these with the actual types used in your application.\n",
    "\n",
    "This should be more in line with modern C++ practices.</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1761329b",
   "metadata": {},
   "source": [
    "\n",
    "### Header Files\n",
    "```cpp\n",
    "#include <cstdint>\n",
    "```\n",
    "- I included `<cstdint>` to explicitly use the standard header for fixed-width integer types.\n",
    "\n",
    "### Function Arguments and Error Handling\n",
    "```cpp\n",
    "if (nrhs < 5) {\n",
    "    mexErrMsgIdAndTxt(\"MATLAB:mexFunction:invalidNumInputs\",\n",
    "                      \"At least 5 input arguments required.\");\n",
    "}\n",
    "if (nlhs > 1) {\n",
    "    mexErrMsgIdAndTxt(\"MATLAB:mexFunction:invalidNumOutputs\",\n",
    "                      \"Too many output arguments.\");\n",
    "}\n",
    "```\n",
    "- Added error checks for the number of input (`nrhs`) and output (`nlhs`) arguments. This helps catch errors where the function is called with an incorrect number of arguments from MATLAB.\n",
    "\n",
    "### Use of `const`\n",
    "```cpp\n",
    "const uint32_t func = *reinterpret_cast<const uint32_t*>(mxGetData(prhs[0]));\n",
    "```\n",
    "- Used `const` qualifiers for variables that shouldn't be modified after they are initialized. This makes the code safer and more maintainable.\n",
    "\n",
    "### Type Casting\n",
    "```cpp\n",
    "*reinterpret_cast<const uint32_t*>(mxGetData(prhs[0]));\n",
    "```\n",
    "- Replaced C-style casts with C++-style `reinterpret_cast` for better type safety and readability.\n",
    "\n",
    "### Loop Counter\n",
    "```cpp\n",
    "for (int m = 0; m < 2; ++m)\n",
    "```\n",
    "- Used the prefix increment (`++m`) instead of postfix (`m++`). Although it doesn't make a difference for built-in types, using prefix increment is generally more efficient for complex types and is a good habit to adopt.\n",
    "\n",
    "### `nullptr` instead of `NULL`\n",
    "```cpp\n",
    "pthread_create(&thread, nullptr, &move_fifo_to_pipe, &ctx);\n",
    "```\n",
    "- Replaced `NULL` with `nullptr`. Introduced in C++11, `nullptr` is type-safe and can only be assigned to pointer types, unlike `NULL` or `0`.\n",
    "\n",
    "### `auto` Keyword\n",
    "```cpp\n",
    "auto* the_pipe = pipe_new(sizeof(uint32_t), PIPE_SIZE);\n",
    "auto* prod = pipe_producer_new(the_pipe);\n",
    "auto* cons = pipe_consumer_new(the_pipe);\n",
    "```\n",
    "- Used `auto` for type inference to make the code more concise and easier to maintain. This is particularly useful if the type of the function that you are calling changes in the future.\n",
    "\n",
    "These changes align the code more closely with modern C++ best practices.</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e815df45",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: orange\">5.3 Improve documentation</span></h3>\n",
    "\n",
    "<b>Update the following python function, fix it to adhere to standards and add detailled standard documentation</b>\n",
    "\n",
    "Update the following python function, fix it to adhere to standards and add detailled standard documentation\n",
    "\n",
    "```python\n",
    "def FastPeakDetection(self,Signal , delta, x = None):\n",
    "\n",
    "        if x is None:\n",
    "            x = numpy.arange(len(Signal))\n",
    "\n",
    "        scipy.signal.argrelextrema(Signal, numpy.greater)\n",
    "        # for local minima\n",
    "        argrelextrema(Signal, numpy.less)\n",
    "        \n",
    "        return \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0357f5",
   "metadata": {},
   "source": [
    "<blockquote>Certainly! To adhere to Python standards and best practices, we'll do the following:\n",
    "\n",
    "1. Follow PEP 8 naming conventions and use `snake_case` for function names and variables.\n",
    "2. Add type hints to indicate the expected types of parameters and return values.\n",
    "3. Include a docstring to explain what the function does, its parameters, and its return value.\n",
    "4. Import required modules explicitly.\n",
    "5. Fix the logic for peak detection, as the original code is incomplete.\n",
    "\n",
    "Here's how the updated function might look:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "\n",
    "def fast_peak_detection(self, signal: np.ndarray, delta: float, x: np.ndarray = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform fast peak detection on a given signal.\n",
    "    \n",
    "    Parameters:\n",
    "    - signal (np.ndarray): The input signal on which to perform peak detection.\n",
    "    - delta (float): The threshold for peak detection.\n",
    "    - x (np.ndarray, optional): The x-coordinates corresponding to the signal. \n",
    "      If None, will default to an array [0, 1, ..., len(signal) - 1].\n",
    "    \n",
    "    Returns:\n",
    "    - np.ndarray: An array of indices where peaks are located.\n",
    "    \"\"\"\n",
    "    \n",
    "    if x is None:\n",
    "        x = np.arange(len(signal))\n",
    "        \n",
    "    # For local maxima\n",
    "    local_maxima = scipy.signal.argrelextrema(signal, np.greater)[0]\n",
    "    \n",
    "    # For local minima (if needed)\n",
    "    local_minima = scipy.signal.argrelextrema(signal, np.less)[0]\n",
    "    \n",
    "    # Perform any additional logic here using delta, local_maxima, and local_minima\n",
    "    # For example, filter peaks based on the delta value\n",
    "    \n",
    "    return local_maxima  # Return the indices of local maxima as an example\n",
    "```\n",
    "\n",
    "In this updated function:\n",
    "\n",
    "- I've used `np` and `scipy.signal` as shorthand for `numpy` and `scipy.signal` respectively. This is common practice in scientific Python code.\n",
    "- I've added type hints to indicate that `signal` and `x` are expected to be NumPy arrays and `delta` is expected to be a float. The function is expected to return a NumPy array.\n",
    "- I included a detailed docstring that explains the function's purpose, its parameters, and its return value.\n",
    "\n",
    "Note that I left placeholders for additional logic that you might want to implement, such as filtering peaks based on the `delta` value.</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edcd9ec",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: orange\">5.4 Adjust Figure apparences\n",
    "</span></h3>\n",
    "\n",
    "<b>In python,  make an artificial plot with 3 traces (smooth signal + a bit of noise), with only positive values, then \n",
    "\n",
    "* Put each line in  edifferent color wolloing the matlab \"lines colormap\"\n",
    "* use line and scatter, but have 0.5 opacity\n",
    "* Have a fully white background\n",
    "* no grid\n",
    "* box only at the bottom and left\n",
    "* Use a font as elegant as Times new Roman, but avalable\n",
    "* make up some x and y label\n",
    "* set the tick labels in smaller font than usal\n",
    "* draw a red line in the middle of the x axis spanning the entre y axis. Then at the point of intersection between trace 2 and this line, create a label with a red arrow pointing towards the intersection point, and saying \"here\"\n",
    "* Add any other changes that would make the figure elgant</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd85cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for plotting and data manipulation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to modify for imports (if required)\n",
    "\n",
    "# Creating artificial data with 3 traces (smooth signal + a bit of noise)\n",
    "x = np.linspace(0, 10, 100)\n",
    "y1 = np.sin(x) + 0.2 * np.random.randn(100)\n",
    "y2 = np.cos(x) + 0.2 * np.random.randn(100)\n",
    "y3 = np.sin(2 * x) + 0.2 * np.random.randn(100)\n",
    "\n",
    "# Ensuring only positive values\n",
    "y1 = np.abs(y1)\n",
    "y2 = np.abs(y2)\n",
    "y3 = np.abs(y3)\n",
    "\n",
    "# Creating the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# MATLAB-like color scheme\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']  # Corresponding to 'b', 'orange', 'g' in MATLAB\n",
    "\n",
    "# Plotting lines and scatter plots with 0.5 opacity\n",
    "plt.plot(x, y1, label='Trace 1', color=colors[0], alpha=0.5)\n",
    "plt.scatter(x, y1, color=colors[0], alpha=0.5)\n",
    "plt.plot(x, y2, label='Trace 2', color=colors[1], alpha=0.5)\n",
    "plt.scatter(x, y2, color=colors[1], alpha=0.5)\n",
    "plt.plot(x, y3, label='Trace 3', color=colors[2], alpha=0.5)\n",
    "plt.scatter(x, y3, color=colors[2], alpha=0.5)\n",
    "\n",
    "# Background, grid, and box\n",
    "plt.gca().set_facecolor('white')\n",
    "plt.grid(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Font settings\n",
    "plt.rc('font', family='serif', serif='Times New Roman')\n",
    "\n",
    "# Labels and tick settings\n",
    "plt.xlabel('Time (s)', fontsize=12)\n",
    "plt.ylabel('Amplitude', fontsize=12)\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "# Red line in the middle of the x-axis\n",
    "plt.axvline(x=5, color='red', linestyle='--')\n",
    "\n",
    "# Finding the intersection between trace 2 and the red line\n",
    "intersection_x = 5\n",
    "intersection_y = np.interp(5, x, y2)\n",
    "plt.annotate('Here', xy=(intersection_x, intersection_y), xycoords='data',\n",
    "             xytext=(intersection_x + 1, intersection_y + 0.2), textcoords='data',\n",
    "             arrowprops=dict(arrowstyle=\"->\", lw=1.5, color='red'),\n",
    "             color='red', fontsize=12)\n",
    "\n",
    "# Adding legend\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "# Additional changes for elegance\n",
    "plt.title('Elegant Plot of 3 Traces', fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1b4c3d",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: orange\">5.4 Other use cases\n",
    "</span></h3>\n",
    "\n",
    "* Load complex csv, hdf5, excel etc...\n",
    "\n",
    "* help with compilation and librairy issues\n",
    "* Build regular expression to filter complex filenames (eg : imaging, eeg, ephy recordings)\n",
    "* List methods. You can ask to weight pros and cons and put them in a table\n",
    "* Do some math, including hard stuff\n",
    "* Explain hardware error code \n",
    "* Help chose statistical design\n",
    "* help with github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter contrib nbextension install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf135d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "SummerSchool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

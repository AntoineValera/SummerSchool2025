{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning for Neural Data Analysis\n",
    "# --- Standard Library ---\n",
    "import warnings\n",
    "\n",
    "# --- Scientific Libraries ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, zscore\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# --- Machine Learning ---\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set style\n",
    "sns.set_theme(style=\"white\", context=\"talk\", palette=\"Set2\")\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Computer Modern Roman\", \"Times New Roman\", \"DejaVu Serif\"],\n",
    "    \"text.usetex\": False,\n",
    "    \"axes.labelsize\": 13,\n",
    "    \"axes.titlesize\": 15,\n",
    "    \"legend.fontsize\": 11,\n",
    "    \"xtick.labelsize\": 11,\n",
    "    \"ytick.labelsize\": 11,\n",
    "    \"axes.linewidth\": 0.6,\n",
    "    \"axes.edgecolor\": \"0.2\",\n",
    "})\n",
    "print(\"=== MACHINE LEARNING FOR NEURAL DATA ANALYSIS ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c107fc",
   "metadata": {},
   "source": [
    "# 1. Data Preparation\n",
    "Load, clean, and visualize neural and behavioral data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee432976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Preparation: Load, clean, and preprocess neural and behavioral data ---\n",
    "print(\"1. Data Preparation...\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Selector for choosing the dataset\n",
    "dataset_choice = \"population\"  # Change to \"dendrites\" to use the other dataset\n",
    "\n",
    "if dataset_choice == \"dendrites\":\n",
    "    # Load the .mat file for the tree dataset. these were variables directly stored in the .mat file\n",
    "    mat_path = \"Data/M1_dendritic_tree_data.mat\"  # Update this path to the location of your .mat file\n",
    "    mat_data = loadmat(mat_path)\n",
    "\n",
    "    # Extract the variables\n",
    "    behaviour = mat_data['behaviour'].squeeze()  # Squeeze to remove single-dimensional entries\n",
    "    result = mat_data['result']\n",
    "    tax = np.squeeze(mat_data['tax'].T)\n",
    "    coords = mat_data['coords']\n",
    "\n",
    "elif dataset_choice == \"population\":\n",
    "    # Load the .mat file for the M1 dataset. # these were variables stored in a structure in the .mat file\n",
    "    mat_path = \"Data/M1_population_data.mat\"  # Data exported from matlab\n",
    "    mat_data = loadmat(mat_path)\n",
    "\n",
    "    # Extract the variables\n",
    "    mat_data = mat_data['mat_data']\n",
    "    behaviour = mat_data['behaviour'][0, 0].squeeze()  # Indexing to access the nested structure and squeeze to remove single-dimensional entries\n",
    "    result = mat_data['result'][0, 0]  # Indexing to access the nested structure\n",
    "    tax = mat_data['tax'][0, 0].squeeze()  # Indexing to access the nested structure and squeeze to remove single-dimensional entries\n",
    "\n",
    "# Get the dimensions\n",
    "T, N = len(behaviour), result.shape[0]\n",
    "\n",
    "# Ensure result shape is (Individuals, Timepoints)\n",
    "print(result.shape) # N x T\n",
    "print(tax.shape) # T x 1\n",
    "print(behaviour.shape) # T x 1\n",
    "\n",
    "# Align with existing variable names in this notebook\n",
    "behavior = behaviour\n",
    "neural_data = result\n",
    "time_axis = tax\n",
    "\n",
    "if dataset_choice == \"dendrites\":\n",
    "    median_ref = np.nanmedian(neural_data, axis=0, keepdims=True)\n",
    "    neural_data = neural_data - median_ref\n",
    "\n",
    "# Smooth behavioral data with a Gaussian filter\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "behavior = gaussian_filter1d(behavior, sigma=10)\n",
    "\n",
    "# Replace non-finite values with NaN and drop invalid neurons/timepoints\n",
    "neural_data = np.where(np.isfinite(neural_data), neural_data, np.nan)\n",
    "behavior = np.where(np.isfinite(behavior), behavior, np.nan)\n",
    "initial_n_neurons, initial_n_timepoints = neural_data.shape\n",
    "valid_neurons = ~np.all(np.isnan(neural_data), axis=1)\n",
    "neural_data = neural_data[valid_neurons]\n",
    "removed_neurons = initial_n_neurons - neural_data.shape[0]\n",
    "valid_time = ~np.isnan(behavior)\n",
    "valid_time &= ~np.any(np.isnan(neural_data), axis=0)\n",
    "behavior = behavior[valid_time]\n",
    "neural_data = neural_data[:, valid_time]\n",
    "time_axis = time_axis[valid_time]\n",
    "removed_timepoints = initial_n_timepoints - neural_data.shape[1]\n",
    "\n",
    "# Print summary of cleaning\n",
    "n_neurons, n_timepoints = neural_data.shape\n",
    "print(f\"Removed {removed_neurons} neurons and {removed_timepoints} timepoints with NaN\")\n",
    "print(f\"Dataset cleaned: {n_neurons} neurons, {n_timepoints} timepoints\")\n",
    "\n",
    "# Verify no NaNs remain\n",
    "assert not np.isnan(neural_data).any()\n",
    "assert not np.isnan(behavior).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2bc68",
   "metadata": {},
   "source": [
    "# 2. Data Overview\n",
    "Visualize behavior and neural activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998dcd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Overview: Visualize behavior and neural activity ---\n",
    "\n",
    "# Plot behavior and neural activity heatmap\n",
    "fig, (ax_beh, ax_heat) = plt.subplots(\n",
    "    2, 1, figsize=(14, 6), gridspec_kw={\"height_ratios\": [1, 3]}, sharex=True\n",
    ")\n",
    "\n",
    "ax_beh.plot(time_axis, behavior, color=\"tab:red\", linewidth=1.5)\n",
    "ax_beh.set_ylabel(\"Behavior\")\n",
    "sns.despine(ax=ax_beh, bottom=True)\n",
    "ax_beh.grid(False)\n",
    "\n",
    "neural_z = zscore(neural_data, axis=1)\n",
    "im = ax_heat.imshow(\n",
    "    neural_z,\n",
    "    aspect=\"auto\",\n",
    "    cmap=\"viridis\",\n",
    "    extent=[time_axis[0], time_axis[-1], 0, n_neurons],\n",
    "    vmin=-2,\n",
    "    vmax=2,\n",
    "    interpolation=\"none\",\n",
    ")\n",
    "ax_heat.set_ylabel(\"Neuron #\")\n",
    "ax_heat.set_xlabel(\"Time (s)\")\n",
    "ax_heat.set_title(\"Neural activity (z-scored)\")\n",
    "sns.despine(ax=ax_heat)\n",
    "ax_heat.grid(False)\n",
    "cbar = fig.colorbar(im, ax=ax_heat, label=\"z-score\", orientation=\"horizontal\", pad=0.2, fraction=0.05)\n",
    "cbar.outline.set_visible(False)\n",
    "\n",
    "fig.suptitle(\"Can we predict behavior from neural activity?\", y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot example neuron activity traces\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "offset = np.nanmax(np.abs(neural_data)) * 1.2\n",
    "palette = sns.color_palette(\"Set2\", n_colors=min(5, n_neurons))\n",
    "for i, color in enumerate(palette):\n",
    "    ax.plot(time_axis, neural_data[i] + i * offset, label=f\"Neuron {i}\", color=color, lw=1)\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Activity (offset)\")\n",
    "ax.set_title(\"Example neuron activity\")\n",
    "ax.legend(ncol=3, frameon=False)\n",
    "sns.despine(ax=ax)\n",
    "ax.grid(False)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3359445",
   "metadata": {},
   "source": [
    "# 3. Linear Regression\n",
    "\n",
    "### Fit a linear model to predict behavior from neural activity.\n",
    "\n",
    "This cell builds a linear decoder that predicts behavior from population neural activity. The features matrix X is set to neural_data.T so that each row is a time point and each column is a neuron, while y is the corresponding behavioral readout at each time. The data are split into a training and test set (70/30) for an unbiased generalization estimate.\n",
    "\n",
    "The model is a Pipeline with StandardScaler followed by Ridge, which standardizes each feature then fits a linear regression with L2 regularization. Standardization makes the penalty comparable across features; Ridge solves for weights by minimizing $||y - Xw||_2^2 + \\alpha ||w||_2^2$ with $\\alpha=1.0$, which stabilizes estimates in the presence of multicollinearity and reduces overfitting. The pipeline is fit only on the training data to avoid leakage, then used to predict on train, test, and the full series (the latter for visualization). Other common approaches include L1 (Lasso) to promote sparse weights, Elastic Net to balance sparsity and stability, or RidgeCV to choose α via cross-validation.\n",
    "\n",
    "Performance is summarized with test-set metrics. The coefficient of determination $R^2 = 1 - \\frac{\\sum_i (y_i-\\hat{y}_i)^2}{\\sum_i (y_i-\\bar{y})^2}$ reports variance explained relative to a constant-mean predictor, while RMSE quantifies average prediction error as $\\sqrt{\\frac{1}{n}\\sum_i (y_i-\\hat{y}_i)^2}$. Pearson’s $r$ measures linear association between predicted and true test targets and is scale-invariant; $r$ can be high even when predictions are biased in scale or offset, whereas $R^2$ penalizes such mismatches.\n",
    "\n",
    "The left plot compares test predictions to ground truth with an identity line: tight clustering around this line indicates accurate predictions and well-calibrated scale. The right plot overlays the model’s predictions (trained on the training split) across the entire time axis to illustrate how closely dynamics are tracked; interpret this as qualitative since it includes the training portion. For temporally ordered data, consider time-aware splits (e.g., TimeSeriesSplit or blocked splits) to respect autocorrelation and prevent optimistic estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Linear Regression: Predict behavior from neural activity ---\n",
    "\n",
    "print(\"\\n2. Linear Regression...\")\n",
    "\n",
    "# Prepare features and target\n",
    "X = neural_data.T\n",
    "y = behavior\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Build and fit linear model with Ridge regularization\n",
    "model = make_pipeline(StandardScaler(), Ridge(alpha=1.0))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train, test, and full data\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_full = model.predict(X)\n",
    "\n",
    "# Evaluate model performance\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "corr_test, _ = pearsonr(y_test, y_pred_test)\n",
    "\n",
    "# --- Plot actual vs predicted behavior ---\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(y_test, y_pred_test, alpha=0.6, s=40)\n",
    "plt.plot([y_test.min(), y_test.max()],[y_test.min(), y_test.max()], \"r--\", linewidth=2)\n",
    "plt.xlabel(\"Actual Behavior\")\n",
    "plt.ylabel(\"Predicted Behavior\")\n",
    "plt.title(f\"Linear model captures behavioral trends\\nR² = {r2_test:.3f}\")\n",
    "plt.text(0.05, 0.95, f\"r = {corr_test:.2f}\", transform=plt.gca().transAxes, va=\"top\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(time_axis, behavior, 'r-', linewidth=0.5, label='Actual', alpha=0.8)\n",
    "plt.plot(time_axis, y_pred_full, 'b-', linewidth=0.5, label='Predicted', alpha=0.8)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Behavior')\n",
    "plt.title('Full Time Series Prediction')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Training R²: {r2_train:.3f}\")\n",
    "print(f\"Test R²: {r2_test:.3f}\")\n",
    "print(f\"Test RMSE: {rmse_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3b6a1",
   "metadata": {},
   "source": [
    "# 4. Model Validation\n",
    "\n",
    "### Cross-validation and regularization analysis.\n",
    "\n",
    "This section evaluates generalization with 5-fold cross-validation using the coefficient of determination. The call to cross_val_score(model, X, y, cv=5, scoring='r2') returns one $R^2$ per fold, where $R^2 = 1 - \\frac{\\sum_i (y_i-\\hat y_i)^2}{\\sum_i (y_i-\\bar y)^2}$. Values near 1 indicate strong predictive fit, 0 matches a mean-only baseline, and negatives mean the model underperforms the baseline. The check for any score below −1 flags extreme misfit that often points to data or setup issues (e.g., scaling, leakage, or mismatched targets).\n",
    "\n",
    "The regularization sweep tests Ridge models across preset $\\alpha$ values by building a Pipeline with StandardScaler and Ridge for each $\\alpha$. Standardizing inside the pipeline ensures each feature contributes comparably and that scaling is learned only on the training fold, preventing leakage. Ridge minimizes $||y - Xw||_2^2 + \\alpha ||w||_2^2$, so increasing $\\alpha$ typically reduces variance at the cost of bias. For each $\\alpha$, cross_val_score yields fold scores whose mean and standard deviation summarize central performance and stability.\n",
    "\n",
    "The plots visualize these results. The left boxplot shows the distribution of $R^2$ across folds for the current model, with the title showing mean ± standard deviation. The right panel plots mean $R^2$ versus $\\alpha$ on a log scale and shades $\\pm$1 standard deviation to indicate variability; the peak suggests a good regularization strength, while drops for very small or large $\\alpha$ indicate under- or over-regularization. If data are temporally ordered, prefer time-aware splits; for broader tuning and automation, consider a denser log-spaced grid with RidgeCV or GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c3ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Validation: Cross-validation and regularization analysis ---\n",
    "\n",
    "print(\"\\n3. Cross-Validation...\")\n",
    "\n",
    "# Cross-validation for model performance\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "\n",
    "# Warn if scores are suspiciously low\n",
    "if np.any(cv_scores < -1):\n",
    "    print('Warning: Some cross-validation scores are very low. Check data scaling and model setup.')\n",
    "\n",
    "# Regularization analysis: test different alpha values\n",
    "alphas = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "mean_scores = []\n",
    "std_scores = []\n",
    "for alpha in alphas:\n",
    "    model_alpha = make_pipeline(StandardScaler(), Ridge(alpha=alpha))\n",
    "    scores = cross_val_score(model_alpha, X, y, cv=5, scoring='r2')\n",
    "    mean_scores.append(scores.mean())\n",
    "    std_scores.append(scores.std())\n",
    "\n",
    "# --- Plot cross-validation results ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=cv_scores, color=\"lightgray\")\n",
    "plt.ylabel(\"R² Score\")\n",
    "plt.title(f\"Consistent prediction accuracy\\nMean R² = {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "mean_scores = np.array(mean_scores)\n",
    "std_scores = np.array(std_scores)\n",
    "plt.semilogx(alphas, mean_scores, \"o-\", linewidth=2)\n",
    "plt.fill_between(alphas, mean_scores - std_scores, mean_scores + std_scores, alpha=0.2)\n",
    "plt.xlabel(\"Regularization Strength (alpha)\")\n",
    "plt.ylabel(\"Cross-Validation R²\")\n",
    "plt.title(\"Regularization Effect\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6d439e",
   "metadata": {},
   "source": [
    "### How to deal with poor cross validation\n",
    "\n",
    "This section evaluates generalization with 5-fold cross-validation using the coefficient of determination. The call to cross_val_score(model, X, y, cv=5, scoring='r2') returns one $R^2$ per fold, where $R^2 = 1 - \\frac{\\sum_i (y_i-\\hat y_i)^2}{\\sum_i (y_i-\\bar y)^2}$. Values near 1 indicate strong predictive fit, 0 matches a mean-only baseline, and negatives mean the model underperforms the baseline. The check for any score below −1 flags extreme misfit that often points to data or setup issues (e.g., scaling, leakage, or mismatched targets).\n",
    "\n",
    "The regularization sweep tests Ridge models across preset $\\alpha$ values by building a Pipeline with StandardScaler and Ridge for each $\\alpha`. Standardizing inside the pipeline ensures each feature contributes comparably and that scaling is learned only on the training fold, preventing leakage. \n",
    "\n",
    "The plots visualize these results. The left boxplot shows the distribution of $R^2$ across folds for the current model, with the title showing mean ± standard deviation. The right panel plots mean $R^2$ versus $\\alpha$ on a log scale and shades $\\pm$1 standard deviation to indicate variability; the peak suggests a good regularization strength, while drops for very small or large $\\alpha` indicate under- or over-regularization. If data are temporally ordered, prefer time-aware splits; for broader tuning and automation, consider a denser log-spaced grid with RidgeCV or GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe970b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve cross-validation scores ---\n",
    "# If CV scores are very low, try tuning alpha and using a robust scaler\n",
    "# and shuffled KFold to better distribute samples across folds.\n",
    "\n",
    "print(\"\\nAttempting to improve cross-validation scores...\")\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Shuffled KFold can help when data ordering biases the folds\n",
    "cv_shuffled = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Tune alpha over a wide log-scale range\n",
    "alphas_tune = np.logspace(-3, 3, 13)\n",
    "\n",
    "# Build updated model: RobustScaler + RidgeCV\n",
    "model = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_tune, cv=cv_shuffled, scoring='r2'))\n",
    "\n",
    "# Fit on training data (pipeline handles scaling internally)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Re-evaluate cross-validation performance with the shuffled CV\n",
    "cv_scores_fixed = cross_val_score(model, X, y, cv=cv_shuffled, scoring='r2')\n",
    "print(f\"New CV Mean R²: {cv_scores_fixed.mean():.3f} ± {cv_scores_fixed.std():.3f}\")\n",
    "\n",
    "if np.any(cv_scores_fixed < 0):\n",
    "    print(\"Note: Some folds still have negative R². Consider domain-specific preprocessing (e.g., detrending, denoising) or TimeSeriesSplit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d23eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Refresh metrics and plots using the tuned model ---\n",
    "\n",
    "# Recompute predictions with the (optionally) tuned model\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_full = model.predict(X)\n",
    "\n",
    "# Recompute metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "from scipy.stats import pearsonr, zscore\n",
    "corr_test, _ = pearsonr(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Updated Training R²: {r2_train:.3f}\")\n",
    "print(f\"Updated Test R²: {r2_test:.3f}\")\n",
    "print(f\"Updated Test RMSE: {rmse_test:.3f}\")\n",
    "print(f\"Updated Test r (Pearson): {corr_test:.2f}\")\n",
    "\n",
    "# Optional: quick overlay plot with updated predictions\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(time_axis, y, 'r-', linewidth=0.5, label='Actual', alpha=0.8)\n",
    "plt.plot(time_axis, y_pred_full, 'b-', linewidth=0.5, label='Predicted (tuned)', alpha=0.8)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Behavior')\n",
    "plt.title('Full Time Series Prediction (Updated)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e128c24e",
   "metadata": {},
   "source": [
    "# 5. Feature Importance\n",
    "\n",
    "### Analyze which neurons are most predictive for behavior.\n",
    "\n",
    "This cell extracts feature importance from a linear Ridge model by fitting it on standardized neural features and visualizing the resulting coefficients per neuron. Standardizing with StandardScaler (fit on X_train only) removes mean and scales each feature to unit variance so that coefficients are comparable across neurons; without this, large-scale features would dominate. The scaler’s statistics are learned on the training set and then applied to both train and test splits to avoid leakage and keep the scale consistent.\n",
    "\n",
    "Ridge is then fit on the scaled training data to obtain coefficients coefs. In a linear model, each coefficient reflects the signed contribution of a neuron to the predicted behavior, conditional on the other neurons. Positive values indicate a direct association and negative values an inverse association. Because Ridge minimizes $||y - Xw||_2^2 + \\alpha ||w||_2^2$, the L2 penalty shrinks weights and tends to distribute them across correlated neurons; as a result, magnitudes are stabilized but may be diluted when features are collinear. With standardized inputs, coefficient magnitudes are directly comparable and serve as a sensible proxy for feature importance (though not a causal measure).\n",
    "\n",
    "The bar plot maps each neuron’s index to its coefficient, using a width that adapts to the number of features to keep bars visible. Interpret larger absolute bars as more influential neurons under the fitted linear decoder. If the target were multi-output, coefs would be 2D and you’d typically select one target or aggregate across targets before plotting. Minor notes: ColumnTransformer is imported but unused here; it can be removed. Also, X_test_scaled is computed but not used in this cell. If your features are sparse, set StandardScaler(with_mean=False) to avoid errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9d438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Importance: Ridge Regression coefficients (with scaling) ---\n",
    "\n",
    "# Use the same scaling as the model for fair coefficients\n",
    "scaler = StandardScaler()\n",
    "ridge = Ridge(alpha=1.0)\n",
    "\n",
    "# Fit scaler on training data and transform\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "coefs = ridge.coef_\n",
    "\n",
    "# --- Plot coefficients ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Color by sign: positive = red, negative = blue\n",
    "colors = ['#d62728' if c > 0 else '#1f77b4' for c in coefs]\n",
    "\n",
    "# Create bars\n",
    "x_positions = np.arange(len(coefs))\n",
    "bars = plt.bar(x_positions, coefs, color=colors, alpha=0.7, edgecolor='white', linewidth=0.5)\n",
    "\n",
    "# Highlight top features by absolute value\n",
    "top_indices = np.argsort(np.abs(coefs))[-3:]\n",
    "for idx in top_indices:\n",
    "    bars[idx].set_edgecolor('black')\n",
    "    bars[idx].set_linewidth(1.5)\n",
    "    bars[idx].set_alpha(1.0)\n",
    "\n",
    "plt.xlabel('Neuron Index')\n",
    "plt.ylabel('Ridge Coefficient')\n",
    "plt.title('Feature Importance: Ridge Coefficients')\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Simple legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#d62728', label='Positive weights'),\n",
    "    Patch(facecolor='#1f77b4', label='Negative weights')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.grid(True, alpha=0.2, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Feature importance: {len(coefs)} neurons, range [{coefs.min():.3f}, {coefs.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a7858",
   "metadata": {},
   "source": [
    "### Visualize top predictors\n",
    "\n",
    "This cell visualizes which individual neurons the fitted linear decoder relies on most, by overlaying their raw activity traces with the behavioral signal. It first extracts the model’s coefficients. Because the decoder is linear, each coefficient reflects the signed contribution of a neuron’s standardized activity to the predicted behavior: positive weights increase the prediction when the neuron is active, negative weights decrease it.\n",
    "\n",
    "The code then ranks neurons by these weights. Using np.argsort on the 1D coefficient vector, it selects the three largest positive coefficients (top predictors) and the three most negative coefficients (top suppressors). The positive set is reversed to present the strongest first.\n",
    "\n",
    "Notes:\n",
    "- Coefficients come from a model trained on standardized features; magnitudes are comparable across neurons but do not imply causality. With correlated neurons, Ridge spreads weight across features, so “top 3” reflects the regularized solution rather than unique contributions.\n",
    "- Ensure y (behavior) and each neural trace share the same time index; here, earlier cleaning aligned time_axis, behavior, and neural_data across valid timepoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0874efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 3 positive and top 3 negative predictor signals, aligned with behavior\n",
    "\n",
    "# Get coefficients from the trained model\n",
    "if hasattr(model, \"named_steps\"):\n",
    "    if \"ridge\" in model.named_steps:\n",
    "        coefs = model.named_steps[\"ridge\"].coef_\n",
    "    elif \"ridgecv\" in model.named_steps:\n",
    "        coefs = model.named_steps[\"ridgecv\"].coef_\n",
    "else:\n",
    "    # Fallback: fit quick model\n",
    "    _sc = StandardScaler()\n",
    "    _rd = Ridge(alpha=1.0)\n",
    "    _rd.fit(_sc.fit_transform(X_train), y_train)\n",
    "    coefs = _rd.coef_\n",
    "\n",
    "# Select top 3 positive and negative neurons\n",
    "pos_indices = np.argsort(coefs)[-3:][::-1]  # Top 3 positive (descending)\n",
    "neg_indices = np.argsort(coefs)[:3]         # Top 3 negative (ascending)\n",
    "\n",
    "# Create single plot with stacked traces\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Plot behavior at top\n",
    "ax.plot(time_axis, behavior + 25, 'k-', lw=2, label='Behavior')\n",
    "\n",
    "# Plot neural traces with offset and color coding\n",
    "offset = np.std(neural_data) * 10  # Use 3x std for good spacing\n",
    "\n",
    "for i, idx in enumerate(pos_indices):\n",
    "    color = 'green' if coefs[idx] > 0 else 'red'\n",
    "    ax.plot(time_axis, neural_data[idx] + offset * (len(pos_indices) - i), color=color, lw=1.5, \n",
    "            label=f'Neuron {idx} ({coefs[idx]:.3f})')\n",
    "\n",
    "for i, idx in enumerate(neg_indices):\n",
    "    color = 'green' if coefs[idx] > 0 else 'red'\n",
    "    ax.plot(time_axis, neural_data[idx] + offset * (len(neg_indices) - i - len(pos_indices)), color=color, lw=1.5,\n",
    "            label=f'Neuron {idx} ({coefs[idx]:.3f})')\n",
    "\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Signal (offset)')\n",
    "ax.set_title('Behavior and Top Predictor Neurons')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top positive neurons:\", pos_indices.tolist())\n",
    "print(\"Top negative neurons:\", neg_indices.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eeed0d",
   "metadata": {},
   "source": [
    "# 6. Classifier\n",
    "\n",
    "This section builds a minimal baseline classifier and then a corrected, time-aware version for imbalanced time-series labels.\n",
    "\n",
    "- Label: $y_\\text{bin} = 1(|y| > 0.1)$ → \"active\" vs \"inactive\".\n",
    "- Basic run: one train/test split with `StandardScaler → LogisticRegression`.\n",
    "- Corrected run: block-aware split to limit temporal leakage + `class_weight='balanced'` + proper metrics.\n",
    "\n",
    "Why two runs? The first is a quick gross baseline. The second reflects best practices for imbalanced, autocorrelated data.\n",
    "\n",
    "Notes and ideas to go further:\n",
    "- Tune the amplitude threshold or decision threshold using PR curves (optimize recall/F1).\n",
    "- Report balanced accuracy, precision/recall/F1; accuracy alone can be misleading under imbalance.\n",
    "- Prefer time-aware splits (GroupShuffleSplit/TimeSeriesSplit) to avoid temporal leakage.\n",
    "- If positives are rare, try `class_weight='balanced'` or resampling; calibrate probabilities if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7f7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, classification_report, matthews_corrcoef\n",
    "from collections import Counter\n",
    "\n",
    "# --- Publication-quality plot settings ---\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Computer Modern Roman\", \"Times New Roman\", \"DejaVu Serif\"],\n",
    "    \"axes.labelsize\": 13,\n",
    "    \"axes.titlesize\": 15,\n",
    "    \"legend.fontsize\": 11,\n",
    "    \"xtick.labelsize\": 11,\n",
    "    \"ytick.labelsize\": 11,\n",
    "    \"axes.linewidth\": 0.7,\n",
    "    \"axes.edgecolor\": \"0.2\",\n",
    "})\n",
    "\n",
    "# =============================================================================\n",
    "# Basic gross classification (single run, no CV)\n",
    "# =============================================================================\n",
    "\n",
    "# Binary labels using symmetric threshold ±0.1\n",
    "y_binary = (np.abs(y) > 0.1).astype(int)\n",
    "\n",
    "# Visual check: behavior with active intervals and threshold lines\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(time_axis, y, 'k-', linewidth=1.3, label='Behavior')\n",
    "plt.fill_between(time_axis, y.min(), y.max(), where=(y_binary == 1), color='orange', alpha=0.25, label='Active (|y|>0.1)')\n",
    "plt.axhline(0.1, color='gray', ls='--', lw=1)\n",
    "plt.axhline(-0.1, color='gray', ls='--', lw=1)\n",
    "plt.xlabel('Time (s)'); plt.ylabel('Behavior'); plt.title('Behavior with Binary Labels (±0.1)')\n",
    "plt.legend(frameon=False); plt.grid(False)\n",
    "for s in plt.gca().spines.values(): s.set_visible(False)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Show class distribution\n",
    "class_counts = Counter(y_binary)\n",
    "print(f\"Class distribution: {class_counts[0]} vs {class_counts[1]} ({class_counts[0]/len(y_binary)*100:.1f}% vs {class_counts[1]/len(y_binary)*100:.1f}%)\")\n",
    "\n",
    "# Train basic classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=42, stratify=y_binary)\n",
    "clf_basic = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
    "clf_basic.fit(X_train, y_train)\n",
    "y_pred_basic = clf_basic.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_basic)\n",
    "bacc = balanced_accuracy_score(y_test, y_pred_basic)\n",
    "mcc = matthews_corrcoef(y_test, y_pred_basic)\n",
    "print(f'Basic accuracy: {acc:.3f} | Balanced accuracy: {bacc:.3f} | MCC: {mcc:.3f}')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Original distribution (darker color, log scale)\n",
    "axes[0].hist(y, bins=50, alpha=0.85, color='#003366')\n",
    "axes[0].axhline(0, color='white', lw=0.5)\n",
    "axes[0].axvline(0.0, color='gray', ls=':')\n",
    "axes[0].axvline(0.1, color='gray', ls='--'); axes[0].axvline(-0.1, color='gray', ls='--')\n",
    "axes[0].set_title('Behavior distribution (log y-axis)')\n",
    "axes[0].set_xlabel('y'); axes[0].set_ylabel('Count (log)')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].grid(False)\n",
    "for s in axes[0].spines.values(): s.set_visible(False)\n",
    "\n",
    "# Class imbalance\n",
    "axes[1].bar(['Class 0', 'Class 1'], [class_counts[0], class_counts[1]], color=['#D2691E', '#228B22'], alpha=0.85)\n",
    "axes[1].set_title('Class Distribution')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].grid(False)\n",
    "for s in axes[1].spines.values(): s.set_visible(False)\n",
    "\n",
    "# Basic confusion matrix\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_basic), annot=True, fmt='d', ax=axes[2], cbar=False, cmap='Blues')\n",
    "axes[2].set_title('Confusion matrix (basic)')\n",
    "axes[2].set_xlabel('Predicted')\n",
    "axes[2].set_ylabel('Actual')\n",
    "axes[2].grid(False)\n",
    "for s in axes[2].spines.values(): s.set_visible(False)\n",
    "\n",
    "fig.suptitle('Basic single run (no CV)', y=1.02, fontsize=16)\n",
    "fig.tight_layout(); plt.show()\n",
    "\n",
    "# Optional: detailed report (can be long if printed inline)\n",
    "print(classification_report(y_test, y_pred_basic, digits=3))\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cdecd5",
   "metadata": {},
   "source": [
    "MCC (Matthews Correlation Coefficient) uses all four quadrants of the confusion matrix. It returns a value between -1 and 1 and remains reliable even with imbalanced classes, making it a robust measure of binary classification quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3885afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Time-aware, class-balanced single run\n",
    "# =============================================================================\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, f1_score, balanced_accuracy_score, matthews_corrcoef\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Group by time blocks to limit temporal leakage (tune block_sec to your data)\n",
    "block_sec = 5.0  # e.g., 0.5–10.0 depending on autocorrelation\n",
    "groups = np.floor((time_axis - time_axis.min()) / block_sec).astype(int)\n",
    "\n",
    "def _ix(a, idx):\n",
    "    return a.iloc[idx] if hasattr(a, 'iloc') else a[idx]\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.30, random_state=42)\n",
    "tr_idx, te_idx = next(gss.split(X, y_binary, groups=groups))\n",
    "X_tr, X_te = _ix(X, tr_idx), _ix(X, te_idx)\n",
    "y_tr, y_te = y_binary[tr_idx], y_binary[te_idx]\n",
    "\n",
    "# Balanced logistic regression in a scaling pipeline\n",
    "clf_bal = make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42))\n",
    "clf_bal.fit(X_tr, y_tr)\n",
    "y_pred_test = clf_bal.predict(X_te)\n",
    "proba_te = clf_bal.predict_proba(X_te)[:, 1]\n",
    "\n",
    "# Metrics that are robust to imbalance\n",
    "bacc_w = balanced_accuracy_score(y_te, y_pred_test)\n",
    "f1_w = f1_score(y_te, y_pred_test, zero_division=0)\n",
    "ap = average_precision_score(y_te, proba_te)\n",
    "mcc_w = matthews_corrcoef(y_te, y_pred_test)\n",
    "print(f'Time-aware balanced run → BalAcc: {bacc_w:.3f} | F1(+): {f1_w:.3f} | MCC: {mcc_w:.3f} | PR-AUC: {ap:.3f}')\n",
    "\n",
    "# Precision-Recall curve\n",
    "P, R, thr = precision_recall_curve(y_te, proba_te)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(R, P, lw=2, label=f'Balanced (AP={ap:.3f})')\n",
    "plt.xlabel('Recall (positive)'); plt.ylabel('Precision')\n",
    "plt.title('PR curve (time-aware split)')\n",
    "plt.legend(frameon=False); plt.grid(False)\n",
    "for s in plt.gca().spines.values(): s.set_visible(False)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Optional: tune decision threshold for recall (example target)\n",
    "target_recall = 0.90\n",
    "mask = R[:-1] >= target_recall\n",
    "if np.any(mask):\n",
    "    thr_opt = thr[np.argmax(mask)]\n",
    "    yhat_opt = (proba_te >= thr_opt).astype(int)\n",
    "    print(f'Threshold tuned for ~{target_recall:.0%} recall → thr={thr_opt:.3f}, F1(+): {f1_score(y_te, yhat_opt, zero_division=0):.3f}')\n",
    "else:\n",
    "    print('Target recall not achievable from PR curve.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SummerSchool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
